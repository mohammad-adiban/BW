{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349b9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1f35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import V_CNN\n",
    "from models.models import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d64f4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb40c142cd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099b97ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/938], VAE Loss: -965839.3125\n",
      "Epoch [1/10], Step [200/938], VAE Loss: -1216184.1250\n",
      "Epoch [1/10], Step [300/938], VAE Loss: -1467345.5000\n",
      "Epoch [1/10], Step [400/938], VAE Loss: -1764519.8750\n",
      "Epoch [1/10], Step [500/938], VAE Loss: -1941797.3750\n",
      "Epoch [1/10], Step [600/938], VAE Loss: -2009008.2500\n",
      "Epoch [1/10], Step [700/938], VAE Loss: -2021194.1250\n",
      "Epoch [1/10], Step [800/938], VAE Loss: -2079265.7500\n",
      "Epoch [1/10], Step [900/938], VAE Loss: -2120486.7500\n",
      "Train VAE Loss: -1621779.2911\n",
      "Epoch [2/10], Step [100/938], VAE Loss: -2132811.0000\n",
      "Epoch [2/10], Step [200/938], VAE Loss: -2161532.5000\n",
      "Epoch [2/10], Step [300/938], VAE Loss: -2299018.2500\n",
      "Epoch [2/10], Step [400/938], VAE Loss: -2187028.2500\n",
      "Epoch [2/10], Step [500/938], VAE Loss: -2325315.7500\n",
      "Epoch [2/10], Step [600/938], VAE Loss: -2249390.7500\n",
      "Epoch [2/10], Step [700/938], VAE Loss: -2290302.0000\n",
      "Epoch [2/10], Step [800/938], VAE Loss: -2287128.7500\n",
      "Epoch [2/10], Step [900/938], VAE Loss: -2347751.7500\n",
      "Train VAE Loss: -2238790.6234\n",
      "Epoch [3/10], Step [100/938], VAE Loss: -2304929.7500\n",
      "Epoch [3/10], Step [200/938], VAE Loss: -2314887.2500\n",
      "Epoch [3/10], Step [300/938], VAE Loss: -2384267.7500\n",
      "Epoch [3/10], Step [400/938], VAE Loss: -2371300.7500\n",
      "Epoch [3/10], Step [500/938], VAE Loss: -2392806.5000\n",
      "Epoch [3/10], Step [600/938], VAE Loss: -2405781.5000\n",
      "Epoch [3/10], Step [700/938], VAE Loss: -2384220.7500\n",
      "Epoch [3/10], Step [800/938], VAE Loss: -2354379.5000\n",
      "Epoch [3/10], Step [900/938], VAE Loss: -2404274.2500\n",
      "Train VAE Loss: -2359937.2628\n",
      "Epoch [4/10], Step [100/938], VAE Loss: -2389767.7500\n",
      "Epoch [4/10], Step [200/938], VAE Loss: -2395560.7500\n",
      "Epoch [4/10], Step [300/938], VAE Loss: -2370485.5000\n",
      "Epoch [4/10], Step [400/938], VAE Loss: -2399901.2500\n",
      "Epoch [4/10], Step [500/938], VAE Loss: -2405988.0000\n",
      "Epoch [4/10], Step [600/938], VAE Loss: -2445639.7500\n",
      "Epoch [4/10], Step [700/938], VAE Loss: -2436476.2500\n",
      "Epoch [4/10], Step [800/938], VAE Loss: -2446111.5000\n",
      "Epoch [4/10], Step [900/938], VAE Loss: -2459414.5000\n",
      "Train VAE Loss: -2411431.5589\n",
      "Epoch [5/10], Step [100/938], VAE Loss: -2390968.2500\n",
      "Epoch [5/10], Step [200/938], VAE Loss: -2433378.0000\n",
      "Epoch [5/10], Step [300/938], VAE Loss: -2424820.2500\n",
      "Epoch [5/10], Step [400/938], VAE Loss: -2395366.2500\n",
      "Epoch [5/10], Step [500/938], VAE Loss: -2409331.7500\n",
      "Epoch [5/10], Step [600/938], VAE Loss: -2410839.5000\n",
      "Epoch [5/10], Step [700/938], VAE Loss: -2441315.7500\n",
      "Epoch [5/10], Step [800/938], VAE Loss: -2435474.0000\n",
      "Epoch [5/10], Step [900/938], VAE Loss: -2449615.5000\n",
      "Train VAE Loss: -2439611.9015\n",
      "Epoch [6/10], Step [100/938], VAE Loss: -2491749.0000\n",
      "Epoch [6/10], Step [200/938], VAE Loss: -2445496.0000\n",
      "Epoch [6/10], Step [300/938], VAE Loss: -2461556.2500\n",
      "Epoch [6/10], Step [400/938], VAE Loss: -2482206.0000\n",
      "Epoch [6/10], Step [500/938], VAE Loss: -2482399.5000\n",
      "Epoch [6/10], Step [600/938], VAE Loss: -2418868.7500\n",
      "Epoch [6/10], Step [700/938], VAE Loss: -2397730.2500\n",
      "Epoch [6/10], Step [800/938], VAE Loss: -2477017.5000\n",
      "Epoch [6/10], Step [900/938], VAE Loss: -2510889.7500\n",
      "Train VAE Loss: -2460616.3953\n",
      "Epoch [7/10], Step [100/938], VAE Loss: -2470139.5000\n",
      "Epoch [7/10], Step [200/938], VAE Loss: -2505003.2500\n",
      "Epoch [7/10], Step [300/938], VAE Loss: -2479726.2500\n",
      "Epoch [7/10], Step [400/938], VAE Loss: -2460902.7500\n",
      "Epoch [7/10], Step [500/938], VAE Loss: -2517116.5000\n",
      "Epoch [7/10], Step [600/938], VAE Loss: -2527350.5000\n",
      "Epoch [7/10], Step [700/938], VAE Loss: -2453358.0000\n",
      "Epoch [7/10], Step [800/938], VAE Loss: -2473574.2500\n",
      "Epoch [7/10], Step [900/938], VAE Loss: -2498142.2500\n",
      "Train VAE Loss: -2474990.9136\n",
      "Epoch [8/10], Step [100/938], VAE Loss: -2452231.7500\n",
      "Epoch [8/10], Step [200/938], VAE Loss: -2505078.7500\n",
      "Epoch [8/10], Step [300/938], VAE Loss: -2520523.2500\n",
      "Epoch [8/10], Step [400/938], VAE Loss: -2462919.5000\n",
      "Epoch [8/10], Step [500/938], VAE Loss: -2525915.2500\n",
      "Epoch [8/10], Step [600/938], VAE Loss: -2450399.2500\n",
      "Epoch [8/10], Step [700/938], VAE Loss: -2482686.7500\n",
      "Epoch [8/10], Step [800/938], VAE Loss: -2549945.2500\n",
      "Epoch [8/10], Step [900/938], VAE Loss: -2507735.2500\n",
      "Train VAE Loss: -2485988.9100\n",
      "Epoch [9/10], Step [100/938], VAE Loss: -2472801.0000\n",
      "Epoch [9/10], Step [200/938], VAE Loss: -2523654.5000\n",
      "Epoch [9/10], Step [300/938], VAE Loss: -2518663.7500\n",
      "Epoch [9/10], Step [400/938], VAE Loss: -2477760.5000\n",
      "Epoch [9/10], Step [500/938], VAE Loss: -2448211.0000\n",
      "Epoch [9/10], Step [600/938], VAE Loss: -2503224.5000\n",
      "Epoch [9/10], Step [700/938], VAE Loss: -2472274.5000\n",
      "Epoch [9/10], Step [800/938], VAE Loss: -2517657.7500\n",
      "Epoch [9/10], Step [900/938], VAE Loss: -2441867.2500\n",
      "Train VAE Loss: -2495073.9901\n",
      "Epoch [10/10], Step [100/938], VAE Loss: -2518612.7500\n",
      "Epoch [10/10], Step [200/938], VAE Loss: -2501839.0000\n",
      "Epoch [10/10], Step [300/938], VAE Loss: -2530538.5000\n",
      "Epoch [10/10], Step [400/938], VAE Loss: -2451727.0000\n",
      "Epoch [10/10], Step [500/938], VAE Loss: -2453959.5000\n",
      "Epoch [10/10], Step [600/938], VAE Loss: -2534711.0000\n",
      "Epoch [10/10], Step [700/938], VAE Loss: -2533382.5000\n",
      "Epoch [10/10], Step [800/938], VAE Loss: -2502930.2500\n",
      "Epoch [10/10], Step [900/938], VAE Loss: -2501819.5000\n",
      "Train VAE Loss: -2503022.5981\n"
     ]
    }
   ],
   "source": [
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Create an instance of the VAE\n",
    "vae = VAE().to(device)\n",
    "\n",
    "# Define the loss function and optimizer for VAE\n",
    "vae_criterion = nn.BCELoss()\n",
    "vae_optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop for VAE\n",
    "vae_num_epochs = 10\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar):\n",
    "    # Reconstruction loss\n",
    "    recon_loss = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # KL divergence loss\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # Total VAE loss\n",
    "    vae_loss = recon_loss + kl_loss\n",
    "\n",
    "    return vae_loss\n",
    "\n",
    "\n",
    "for epoch in range(vae_num_epochs):\n",
    "    vae.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch_idx, (images, _) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "\n",
    "        vae_optimizer.zero_grad()\n",
    "        recon_images, mu, logvar = vae(images)\n",
    "        #vae_loss = vae_loss_function(recon_images, images, mu, logvar)\n",
    "        vae_loss = vae_loss_function(recon_images.view(-1, 784), images.view(-1, 784), mu, logvar)\n",
    "        vae_loss.backward()\n",
    "        vae_optimizer.step()\n",
    "\n",
    "        train_loss += vae_loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{vae_num_epochs}], Step [{batch_idx + 1}/{len(train_loader)}], '\n",
    "                  f'VAE Loss: {vae_loss.item():.4f}')\n",
    "\n",
    "    print(f'Train VAE Loss: {train_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a63a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        mu, logvar = vae.encode(images)\n",
    "        features = vae.reparameterize(mu, logvar)\n",
    "        train_labels.extend(labels.numpy())\n",
    "        train_features.append(features.unsqueeze(1))\n",
    "\n",
    "train_features = torch.cat(train_features, dim=0)\n",
    "train_features = train_features.view(60000,1,8,8)\n",
    "\n",
    "# Print the shape of train_features\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece11ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        mu, logvar = vae.encode(images)\n",
    "        features = vae.reparameterize(mu, logvar)\n",
    "        test_labels.extend(labels.numpy())\n",
    "        test_features.append(features.unsqueeze(1))\n",
    "\n",
    "test_features = torch.cat(test_features, dim=0)\n",
    "test_features = test_features.view(10000,1,8,8)\n",
    "\n",
    "# Print the shape of test_features\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b761a78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77629/1021885846.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_features = torch.tensor(train_features)\n",
      "/tmp/ipykernel_77629/1021885846.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_features = torch.tensor(test_features)\n"
     ]
    }
   ],
   "source": [
    "# Convert the features to tensors\n",
    "train_features = torch.tensor(train_features)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_features = torch.tensor(test_features)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Create new datasets with the extracted VAE features\n",
    "train_dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "# Define data loaders for the new datasets\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19558bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/938], Loss: 0.6387\n",
      "Epoch [1/10], Step [200/938], Loss: 0.3592\n",
      "Epoch [1/10], Step [300/938], Loss: 0.2782\n",
      "Epoch [1/10], Step [400/938], Loss: 0.4082\n",
      "Epoch [1/10], Step [500/938], Loss: 0.2477\n",
      "Epoch [1/10], Step [600/938], Loss: 0.2072\n",
      "Epoch [1/10], Step [700/938], Loss: 0.1504\n",
      "Epoch [1/10], Step [800/938], Loss: 0.1352\n",
      "Epoch [1/10], Step [900/938], Loss: 0.1787\n",
      "Train Accuracy: 88.30%\n",
      "Epoch [2/10], Step [100/938], Loss: 0.1034\n",
      "Epoch [2/10], Step [200/938], Loss: 0.1634\n",
      "Epoch [2/10], Step [300/938], Loss: 0.2081\n",
      "Epoch [2/10], Step [400/938], Loss: 0.1668\n",
      "Epoch [2/10], Step [500/938], Loss: 0.1700\n",
      "Epoch [2/10], Step [600/938], Loss: 0.0698\n",
      "Epoch [2/10], Step [700/938], Loss: 0.0758\n",
      "Epoch [2/10], Step [800/938], Loss: 0.1939\n",
      "Epoch [2/10], Step [900/938], Loss: 0.0725\n",
      "Train Accuracy: 94.64%\n",
      "Epoch [3/10], Step [100/938], Loss: 0.1599\n",
      "Epoch [3/10], Step [200/938], Loss: 0.2285\n",
      "Epoch [3/10], Step [300/938], Loss: 0.0777\n",
      "Epoch [3/10], Step [400/938], Loss: 0.2277\n",
      "Epoch [3/10], Step [500/938], Loss: 0.2530\n",
      "Epoch [3/10], Step [600/938], Loss: 0.0913\n",
      "Epoch [3/10], Step [700/938], Loss: 0.0987\n",
      "Epoch [3/10], Step [800/938], Loss: 0.1561\n",
      "Epoch [3/10], Step [900/938], Loss: 0.0968\n",
      "Train Accuracy: 95.71%\n",
      "Epoch [4/10], Step [100/938], Loss: 0.0948\n",
      "Epoch [4/10], Step [200/938], Loss: 0.0495\n",
      "Epoch [4/10], Step [300/938], Loss: 0.1098\n",
      "Epoch [4/10], Step [400/938], Loss: 0.1410\n",
      "Epoch [4/10], Step [500/938], Loss: 0.1102\n",
      "Epoch [4/10], Step [600/938], Loss: 0.1269\n",
      "Epoch [4/10], Step [700/938], Loss: 0.0848\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0824\n",
      "Epoch [4/10], Step [900/938], Loss: 0.1398\n",
      "Train Accuracy: 96.32%\n",
      "Epoch [5/10], Step [100/938], Loss: 0.1164\n",
      "Epoch [5/10], Step [200/938], Loss: 0.0883\n",
      "Epoch [5/10], Step [300/938], Loss: 0.0531\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0349\n",
      "Epoch [5/10], Step [500/938], Loss: 0.1440\n",
      "Epoch [5/10], Step [600/938], Loss: 0.0680\n",
      "Epoch [5/10], Step [700/938], Loss: 0.1433\n",
      "Epoch [5/10], Step [800/938], Loss: 0.1354\n",
      "Epoch [5/10], Step [900/938], Loss: 0.2057\n",
      "Train Accuracy: 96.96%\n",
      "Epoch [6/10], Step [100/938], Loss: 0.0094\n",
      "Epoch [6/10], Step [200/938], Loss: 0.2750\n",
      "Epoch [6/10], Step [300/938], Loss: 0.1190\n",
      "Epoch [6/10], Step [400/938], Loss: 0.1498\n",
      "Epoch [6/10], Step [500/938], Loss: 0.0271\n",
      "Epoch [6/10], Step [600/938], Loss: 0.1235\n",
      "Epoch [6/10], Step [700/938], Loss: 0.1605\n",
      "Epoch [6/10], Step [800/938], Loss: 0.1090\n",
      "Epoch [6/10], Step [900/938], Loss: 0.0879\n",
      "Train Accuracy: 97.34%\n",
      "Epoch [7/10], Step [100/938], Loss: 0.1168\n",
      "Epoch [7/10], Step [200/938], Loss: 0.0471\n",
      "Epoch [7/10], Step [300/938], Loss: 0.0716\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0686\n",
      "Epoch [7/10], Step [500/938], Loss: 0.0619\n",
      "Epoch [7/10], Step [600/938], Loss: 0.0563\n",
      "Epoch [7/10], Step [700/938], Loss: 0.2167\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0833\n",
      "Epoch [7/10], Step [900/938], Loss: 0.0202\n",
      "Train Accuracy: 97.62%\n",
      "Epoch [8/10], Step [100/938], Loss: 0.0223\n",
      "Epoch [8/10], Step [200/938], Loss: 0.0261\n",
      "Epoch [8/10], Step [300/938], Loss: 0.1022\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0177\n",
      "Epoch [8/10], Step [500/938], Loss: 0.2119\n",
      "Epoch [8/10], Step [600/938], Loss: 0.0296\n",
      "Epoch [8/10], Step [700/938], Loss: 0.0630\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0946\n",
      "Epoch [8/10], Step [900/938], Loss: 0.0519\n",
      "Train Accuracy: 97.91%\n",
      "Epoch [9/10], Step [100/938], Loss: 0.0201\n",
      "Epoch [9/10], Step [200/938], Loss: 0.0825\n",
      "Epoch [9/10], Step [300/938], Loss: 0.0176\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0156\n",
      "Epoch [9/10], Step [500/938], Loss: 0.0445\n",
      "Epoch [9/10], Step [600/938], Loss: 0.1476\n",
      "Epoch [9/10], Step [700/938], Loss: 0.0655\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0512\n",
      "Epoch [9/10], Step [900/938], Loss: 0.0290\n",
      "Train Accuracy: 98.15%\n",
      "Epoch [10/10], Step [100/938], Loss: 0.0275\n",
      "Epoch [10/10], Step [200/938], Loss: 0.1729\n",
      "Epoch [10/10], Step [300/938], Loss: 0.0158\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0949\n",
      "Epoch [10/10], Step [500/938], Loss: 0.0142\n",
      "Epoch [10/10], Step [600/938], Loss: 0.0245\n",
      "Epoch [10/10], Step [700/938], Loss: 0.1867\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0165\n",
      "Epoch [10/10], Step [900/938], Loss: 0.0335\n",
      "Train Accuracy: 98.31%\n",
      "Test Accuracy: 96.94%\n",
      "Test Loss: 0.1108\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the CNN\n",
    "model = V_CNN().to(device)\n",
    "\n",
    "# Define the loss function and optimizer for the CNN\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop for the CNN\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(train_loader)}], '\n",
    "                  f'Loss: {loss.item():.4f}')\n",
    "\n",
    "    print(f'Train Accuracy: {(100 * correct / total):.2f}%')\n",
    "\n",
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = (100 * correct / total)\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc69e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
