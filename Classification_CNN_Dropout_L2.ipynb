{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2215a934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [100/938], Loss: 0.3942\n",
      "Epoch [1/30], Step [200/938], Loss: 0.1766\n",
      "Epoch [1/30], Step [300/938], Loss: 0.2597\n",
      "Epoch [1/30], Step [400/938], Loss: 0.2653\n",
      "Epoch [1/30], Step [500/938], Loss: 0.4031\n",
      "Epoch [1/30], Step [600/938], Loss: 0.1461\n",
      "Epoch [1/30], Step [700/938], Loss: 0.2569\n",
      "Epoch [1/30], Step [800/938], Loss: 0.2043\n",
      "Epoch [1/30], Step [900/938], Loss: 0.1752\n",
      "Train Accuracy: 92.27%\n",
      "Test Accuracy: 97.71%\n",
      "Test Loss: 0.0644\n",
      "Epoch [2/30], Step [100/938], Loss: 0.0696\n",
      "Epoch [2/30], Step [200/938], Loss: 0.0796\n",
      "Epoch [2/30], Step [300/938], Loss: 0.1658\n",
      "Epoch [2/30], Step [400/938], Loss: 0.2993\n",
      "Epoch [2/30], Step [500/938], Loss: 0.1169\n",
      "Epoch [2/30], Step [600/938], Loss: 0.1695\n",
      "Epoch [2/30], Step [700/938], Loss: 0.1894\n",
      "Epoch [2/30], Step [800/938], Loss: 0.2651\n",
      "Epoch [2/30], Step [900/938], Loss: 0.0707\n",
      "Train Accuracy: 96.51%\n",
      "Test Accuracy: 98.58%\n",
      "Test Loss: 0.0457\n",
      "Epoch [3/30], Step [100/938], Loss: 0.0878\n",
      "Epoch [3/30], Step [200/938], Loss: 0.2073\n",
      "Epoch [3/30], Step [300/938], Loss: 0.3075\n",
      "Epoch [3/30], Step [400/938], Loss: 0.0972\n",
      "Epoch [3/30], Step [500/938], Loss: 0.0479\n",
      "Epoch [3/30], Step [600/938], Loss: 0.0764\n",
      "Epoch [3/30], Step [700/938], Loss: 0.1907\n",
      "Epoch [3/30], Step [800/938], Loss: 0.1698\n",
      "Epoch [3/30], Step [900/938], Loss: 0.1167\n",
      "Train Accuracy: 97.01%\n",
      "Test Accuracy: 98.50%\n",
      "Test Loss: 0.0420\n",
      "Epoch [4/30], Step [100/938], Loss: 0.0685\n",
      "Epoch [4/30], Step [200/938], Loss: 0.1230\n",
      "Epoch [4/30], Step [300/938], Loss: 0.2154\n",
      "Epoch [4/30], Step [400/938], Loss: 0.1104\n",
      "Epoch [4/30], Step [500/938], Loss: 0.1320\n",
      "Epoch [4/30], Step [600/938], Loss: 0.0775\n",
      "Epoch [4/30], Step [700/938], Loss: 0.0431\n",
      "Epoch [4/30], Step [800/938], Loss: 0.0955\n",
      "Epoch [4/30], Step [900/938], Loss: 0.0886\n",
      "Train Accuracy: 97.36%\n",
      "Test Accuracy: 98.59%\n",
      "Test Loss: 0.0399\n",
      "Epoch [5/30], Step [100/938], Loss: 0.0527\n",
      "Epoch [5/30], Step [200/938], Loss: 0.0662\n",
      "Epoch [5/30], Step [300/938], Loss: 0.1659\n",
      "Epoch [5/30], Step [400/938], Loss: 0.0766\n",
      "Epoch [5/30], Step [500/938], Loss: 0.0531\n",
      "Epoch [5/30], Step [600/938], Loss: 0.1283\n",
      "Epoch [5/30], Step [700/938], Loss: 0.0430\n",
      "Epoch [5/30], Step [800/938], Loss: 0.1554\n",
      "Epoch [5/30], Step [900/938], Loss: 0.0481\n",
      "Train Accuracy: 97.54%\n",
      "Test Accuracy: 98.70%\n",
      "Test Loss: 0.0396\n",
      "Epoch [6/30], Step [100/938], Loss: 0.2066\n",
      "Epoch [6/30], Step [200/938], Loss: 0.1100\n",
      "Epoch [6/30], Step [300/938], Loss: 0.2174\n",
      "Epoch [6/30], Step [400/938], Loss: 0.1609\n",
      "Epoch [6/30], Step [500/938], Loss: 0.1591\n",
      "Epoch [6/30], Step [600/938], Loss: 0.1621\n",
      "Epoch [6/30], Step [700/938], Loss: 0.1393\n",
      "Epoch [6/30], Step [800/938], Loss: 0.1640\n",
      "Epoch [6/30], Step [900/938], Loss: 0.0568\n",
      "Train Accuracy: 97.61%\n",
      "Test Accuracy: 98.71%\n",
      "Test Loss: 0.0403\n",
      "Epoch [7/30], Step [100/938], Loss: 0.0630\n",
      "Epoch [7/30], Step [200/938], Loss: 0.0954\n",
      "Epoch [7/30], Step [300/938], Loss: 0.1144\n",
      "Epoch [7/30], Step [400/938], Loss: 0.1027\n",
      "Epoch [7/30], Step [500/938], Loss: 0.0853\n",
      "Epoch [7/30], Step [600/938], Loss: 0.1034\n",
      "Epoch [7/30], Step [700/938], Loss: 0.0637\n",
      "Epoch [7/30], Step [800/938], Loss: 0.0517\n",
      "Epoch [7/30], Step [900/938], Loss: 0.1592\n",
      "Train Accuracy: 97.61%\n",
      "Test Accuracy: 98.65%\n",
      "Test Loss: 0.0403\n",
      "Epoch [8/30], Step [100/938], Loss: 0.0684\n",
      "Epoch [8/30], Step [200/938], Loss: 0.0381\n",
      "Epoch [8/30], Step [300/938], Loss: 0.0825\n",
      "Epoch [8/30], Step [400/938], Loss: 0.0798\n",
      "Epoch [8/30], Step [500/938], Loss: 0.1549\n",
      "Epoch [8/30], Step [600/938], Loss: 0.0592\n",
      "Epoch [8/30], Step [700/938], Loss: 0.1316\n",
      "Epoch [8/30], Step [800/938], Loss: 0.1438\n",
      "Epoch [8/30], Step [900/938], Loss: 0.1129\n",
      "Train Accuracy: 97.79%\n",
      "Test Accuracy: 98.76%\n",
      "Test Loss: 0.0375\n",
      "Epoch [9/30], Step [100/938], Loss: 0.1252\n",
      "Epoch [9/30], Step [200/938], Loss: 0.0497\n",
      "Epoch [9/30], Step [300/938], Loss: 0.0567\n",
      "Epoch [9/30], Step [400/938], Loss: 0.0506\n",
      "Epoch [9/30], Step [500/938], Loss: 0.0533\n",
      "Epoch [9/30], Step [600/938], Loss: 0.0849\n",
      "Epoch [9/30], Step [700/938], Loss: 0.1051\n",
      "Epoch [9/30], Step [800/938], Loss: 0.2382\n",
      "Epoch [9/30], Step [900/938], Loss: 0.0908\n",
      "Train Accuracy: 97.83%\n",
      "Test Accuracy: 98.61%\n",
      "Test Loss: 0.0416\n",
      "Epoch [10/30], Step [100/938], Loss: 0.0644\n",
      "Epoch [10/30], Step [200/938], Loss: 0.0381\n",
      "Epoch [10/30], Step [300/938], Loss: 0.0447\n",
      "Epoch [10/30], Step [400/938], Loss: 0.1975\n",
      "Epoch [10/30], Step [500/938], Loss: 0.1084\n",
      "Epoch [10/30], Step [600/938], Loss: 0.0737\n",
      "Epoch [10/30], Step [700/938], Loss: 0.0928\n",
      "Epoch [10/30], Step [800/938], Loss: 0.2752\n",
      "Epoch [10/30], Step [900/938], Loss: 0.0973\n",
      "Train Accuracy: 97.86%\n",
      "Test Accuracy: 98.89%\n",
      "Test Loss: 0.0341\n",
      "Epoch [11/30], Step [100/938], Loss: 0.0725\n",
      "Epoch [11/30], Step [200/938], Loss: 0.0658\n",
      "Epoch [11/30], Step [300/938], Loss: 0.0359\n",
      "Epoch [11/30], Step [400/938], Loss: 0.0765\n",
      "Epoch [11/30], Step [500/938], Loss: 0.0704\n",
      "Epoch [11/30], Step [600/938], Loss: 0.0880\n",
      "Epoch [11/30], Step [700/938], Loss: 0.0275\n",
      "Epoch [11/30], Step [800/938], Loss: 0.0961\n",
      "Epoch [11/30], Step [900/938], Loss: 0.0899\n",
      "Train Accuracy: 97.90%\n",
      "Test Accuracy: 98.85%\n",
      "Test Loss: 0.0342\n",
      "Epoch [12/30], Step [100/938], Loss: 0.1342\n",
      "Epoch [12/30], Step [200/938], Loss: 0.0848\n",
      "Epoch [12/30], Step [300/938], Loss: 0.0864\n",
      "Epoch [12/30], Step [400/938], Loss: 0.0376\n",
      "Epoch [12/30], Step [500/938], Loss: 0.0286\n",
      "Epoch [12/30], Step [600/938], Loss: 0.1196\n",
      "Epoch [12/30], Step [700/938], Loss: 0.1284\n",
      "Epoch [12/30], Step [800/938], Loss: 0.1788\n",
      "Epoch [12/30], Step [900/938], Loss: 0.0611\n",
      "Train Accuracy: 97.97%\n",
      "Test Accuracy: 98.77%\n",
      "Test Loss: 0.0365\n",
      "Epoch [13/30], Step [100/938], Loss: 0.0402\n",
      "Epoch [13/30], Step [200/938], Loss: 0.0528\n",
      "Epoch [13/30], Step [300/938], Loss: 0.0426\n",
      "Epoch [13/30], Step [400/938], Loss: 0.1032\n",
      "Epoch [13/30], Step [500/938], Loss: 0.0482\n",
      "Epoch [13/30], Step [600/938], Loss: 0.0487\n",
      "Epoch [13/30], Step [700/938], Loss: 0.1336\n",
      "Epoch [13/30], Step [800/938], Loss: 0.0391\n",
      "Epoch [13/30], Step [900/938], Loss: 0.0633\n",
      "Train Accuracy: 97.98%\n",
      "Test Accuracy: 98.79%\n",
      "Test Loss: 0.0357\n",
      "Epoch [14/30], Step [100/938], Loss: 0.0806\n",
      "Epoch [14/30], Step [200/938], Loss: 0.0848\n",
      "Epoch [14/30], Step [300/938], Loss: 0.0688\n",
      "Epoch [14/30], Step [400/938], Loss: 0.0873\n",
      "Epoch [14/30], Step [500/938], Loss: 0.1180\n",
      "Epoch [14/30], Step [600/938], Loss: 0.0408\n",
      "Epoch [14/30], Step [700/938], Loss: 0.1242\n",
      "Epoch [14/30], Step [800/938], Loss: 0.1095\n",
      "Epoch [14/30], Step [900/938], Loss: 0.1711\n",
      "Train Accuracy: 98.07%\n",
      "Test Accuracy: 98.80%\n",
      "Test Loss: 0.0365\n",
      "Epoch [15/30], Step [100/938], Loss: 0.0921\n",
      "Epoch [15/30], Step [200/938], Loss: 0.0748\n",
      "Epoch [15/30], Step [300/938], Loss: 0.1608\n",
      "Epoch [15/30], Step [400/938], Loss: 0.1477\n",
      "Epoch [15/30], Step [500/938], Loss: 0.1180\n",
      "Epoch [15/30], Step [600/938], Loss: 0.0410\n",
      "Epoch [15/30], Step [700/938], Loss: 0.0742\n",
      "Epoch [15/30], Step [800/938], Loss: 0.0689\n",
      "Epoch [15/30], Step [900/938], Loss: 0.0332\n",
      "Train Accuracy: 98.08%\n",
      "Test Accuracy: 98.64%\n",
      "Test Loss: 0.0425\n",
      "Epoch [16/30], Step [100/938], Loss: 0.0959\n",
      "Epoch [16/30], Step [200/938], Loss: 0.0340\n",
      "Epoch [16/30], Step [300/938], Loss: 0.1312\n",
      "Epoch [16/30], Step [400/938], Loss: 0.1313\n",
      "Epoch [16/30], Step [500/938], Loss: 0.0422\n",
      "Epoch [16/30], Step [600/938], Loss: 0.1319\n",
      "Epoch [16/30], Step [700/938], Loss: 0.0477\n",
      "Epoch [16/30], Step [800/938], Loss: 0.1631\n",
      "Epoch [16/30], Step [900/938], Loss: 0.0826\n",
      "Train Accuracy: 98.06%\n",
      "Test Accuracy: 98.79%\n",
      "Test Loss: 0.0359\n",
      "Epoch [17/30], Step [100/938], Loss: 0.0683\n",
      "Epoch [17/30], Step [200/938], Loss: 0.0633\n",
      "Epoch [17/30], Step [300/938], Loss: 0.0334\n",
      "Epoch [17/30], Step [400/938], Loss: 0.0383\n",
      "Epoch [17/30], Step [500/938], Loss: 0.1206\n",
      "Epoch [17/30], Step [600/938], Loss: 0.0373\n",
      "Epoch [17/30], Step [700/938], Loss: 0.0532\n",
      "Epoch [17/30], Step [800/938], Loss: 0.0346\n",
      "Epoch [17/30], Step [900/938], Loss: 0.0916\n",
      "Train Accuracy: 98.12%\n",
      "Test Accuracy: 98.84%\n",
      "Test Loss: 0.0358\n",
      "Epoch [18/30], Step [100/938], Loss: 0.0461\n",
      "Epoch [18/30], Step [200/938], Loss: 0.1591\n",
      "Epoch [18/30], Step [300/938], Loss: 0.0471\n",
      "Epoch [18/30], Step [400/938], Loss: 0.0601\n",
      "Epoch [18/30], Step [500/938], Loss: 0.0448\n",
      "Epoch [18/30], Step [600/938], Loss: 0.2800\n",
      "Epoch [18/30], Step [700/938], Loss: 0.0965\n",
      "Epoch [18/30], Step [800/938], Loss: 0.1361\n",
      "Epoch [18/30], Step [900/938], Loss: 0.1341\n",
      "Train Accuracy: 98.04%\n",
      "Test Accuracy: 98.59%\n",
      "Test Loss: 0.0400\n",
      "Epoch [19/30], Step [100/938], Loss: 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Step [200/938], Loss: 0.0318\n",
      "Epoch [19/30], Step [300/938], Loss: 0.0429\n",
      "Epoch [19/30], Step [400/938], Loss: 0.0516\n",
      "Epoch [19/30], Step [500/938], Loss: 0.0592\n",
      "Epoch [19/30], Step [600/938], Loss: 0.1207\n",
      "Epoch [19/30], Step [700/938], Loss: 0.0370\n",
      "Epoch [19/30], Step [800/938], Loss: 0.0982\n",
      "Epoch [19/30], Step [900/938], Loss: 0.2115\n",
      "Train Accuracy: 98.10%\n",
      "Test Accuracy: 98.69%\n",
      "Test Loss: 0.0390\n",
      "Epoch [20/30], Step [100/938], Loss: 0.1096\n",
      "Epoch [20/30], Step [200/938], Loss: 0.1275\n",
      "Epoch [20/30], Step [300/938], Loss: 0.1677\n",
      "Epoch [20/30], Step [400/938], Loss: 0.1407\n",
      "Epoch [20/30], Step [500/938], Loss: 0.0380\n",
      "Epoch [20/30], Step [600/938], Loss: 0.0457\n",
      "Epoch [20/30], Step [700/938], Loss: 0.0757\n",
      "Epoch [20/30], Step [800/938], Loss: 0.1132\n",
      "Epoch [20/30], Step [900/938], Loss: 0.0624\n",
      "Train Accuracy: 98.06%\n",
      "Test Accuracy: 98.69%\n",
      "Test Loss: 0.0370\n",
      "Epoch [21/30], Step [100/938], Loss: 0.0444\n",
      "Epoch [21/30], Step [200/938], Loss: 0.0735\n",
      "Epoch [21/30], Step [300/938], Loss: 0.1289\n",
      "Epoch [21/30], Step [400/938], Loss: 0.0453\n",
      "Epoch [21/30], Step [500/938], Loss: 0.0970\n",
      "Epoch [21/30], Step [600/938], Loss: 0.0929\n",
      "Epoch [21/30], Step [700/938], Loss: 0.0700\n",
      "Epoch [21/30], Step [800/938], Loss: 0.1642\n",
      "Epoch [21/30], Step [900/938], Loss: 0.0317\n",
      "Train Accuracy: 98.14%\n",
      "Test Accuracy: 98.82%\n",
      "Test Loss: 0.0350\n",
      "Epoch [22/30], Step [100/938], Loss: 0.0661\n",
      "Epoch [22/30], Step [200/938], Loss: 0.1051\n",
      "Epoch [22/30], Step [300/938], Loss: 0.0333\n",
      "Epoch [22/30], Step [400/938], Loss: 0.1522\n",
      "Epoch [22/30], Step [500/938], Loss: 0.0704\n",
      "Epoch [22/30], Step [600/938], Loss: 0.1130\n",
      "Epoch [22/30], Step [700/938], Loss: 0.0461\n",
      "Epoch [22/30], Step [800/938], Loss: 0.0424\n",
      "Epoch [22/30], Step [900/938], Loss: 0.0459\n",
      "Train Accuracy: 98.08%\n",
      "Test Accuracy: 99.01%\n",
      "Test Loss: 0.0309\n",
      "Epoch [23/30], Step [100/938], Loss: 0.0857\n",
      "Epoch [23/30], Step [200/938], Loss: 0.0522\n",
      "Epoch [23/30], Step [300/938], Loss: 0.0276\n",
      "Epoch [23/30], Step [400/938], Loss: 0.0976\n",
      "Epoch [23/30], Step [500/938], Loss: 0.1432\n",
      "Epoch [23/30], Step [600/938], Loss: 0.0537\n",
      "Epoch [23/30], Step [700/938], Loss: 0.0878\n",
      "Epoch [23/30], Step [800/938], Loss: 0.0724\n",
      "Epoch [23/30], Step [900/938], Loss: 0.0646\n",
      "Train Accuracy: 98.16%\n",
      "Test Accuracy: 98.95%\n",
      "Test Loss: 0.0320\n",
      "Epoch [24/30], Step [100/938], Loss: 0.0312\n",
      "Epoch [24/30], Step [200/938], Loss: 0.0847\n",
      "Epoch [24/30], Step [300/938], Loss: 0.0788\n",
      "Epoch [24/30], Step [400/938], Loss: 0.0394\n",
      "Epoch [24/30], Step [500/938], Loss: 0.0920\n",
      "Epoch [24/30], Step [600/938], Loss: 0.0472\n",
      "Epoch [24/30], Step [700/938], Loss: 0.2803\n",
      "Epoch [24/30], Step [800/938], Loss: 0.1577\n",
      "Epoch [24/30], Step [900/938], Loss: 0.1014\n",
      "Train Accuracy: 98.06%\n",
      "Test Accuracy: 98.81%\n",
      "Test Loss: 0.0381\n",
      "Epoch [25/30], Step [100/938], Loss: 0.0333\n",
      "Epoch [25/30], Step [200/938], Loss: 0.0273\n",
      "Epoch [25/30], Step [300/938], Loss: 0.0651\n",
      "Epoch [25/30], Step [400/938], Loss: 0.0410\n",
      "Epoch [25/30], Step [500/938], Loss: 0.0527\n",
      "Epoch [25/30], Step [600/938], Loss: 0.0604\n",
      "Epoch [25/30], Step [700/938], Loss: 0.0530\n",
      "Epoch [25/30], Step [800/938], Loss: 0.0533\n",
      "Epoch [25/30], Step [900/938], Loss: 0.1974\n",
      "Train Accuracy: 98.17%\n",
      "Test Accuracy: 98.93%\n",
      "Test Loss: 0.0308\n",
      "Epoch [26/30], Step [100/938], Loss: 0.0757\n",
      "Epoch [26/30], Step [200/938], Loss: 0.1607\n",
      "Epoch [26/30], Step [300/938], Loss: 0.0841\n",
      "Epoch [26/30], Step [400/938], Loss: 0.0899\n",
      "Epoch [26/30], Step [500/938], Loss: 0.1200\n",
      "Epoch [26/30], Step [600/938], Loss: 0.0427\n",
      "Epoch [26/30], Step [700/938], Loss: 0.0370\n",
      "Epoch [26/30], Step [800/938], Loss: 0.0644\n",
      "Epoch [26/30], Step [900/938], Loss: 0.0301\n",
      "Train Accuracy: 98.16%\n",
      "Test Accuracy: 99.02%\n",
      "Test Loss: 0.0329\n",
      "Epoch [27/30], Step [100/938], Loss: 0.0516\n",
      "Epoch [27/30], Step [200/938], Loss: 0.1245\n",
      "Epoch [27/30], Step [300/938], Loss: 0.0531\n",
      "Epoch [27/30], Step [400/938], Loss: 0.0827\n",
      "Epoch [27/30], Step [500/938], Loss: 0.0611\n",
      "Epoch [27/30], Step [600/938], Loss: 0.0459\n",
      "Epoch [27/30], Step [700/938], Loss: 0.0687\n",
      "Epoch [27/30], Step [800/938], Loss: 0.0485\n",
      "Epoch [27/30], Step [900/938], Loss: 0.0412\n",
      "Train Accuracy: 98.17%\n",
      "Test Accuracy: 98.97%\n",
      "Test Loss: 0.0301\n",
      "Epoch [28/30], Step [100/938], Loss: 0.0609\n",
      "Epoch [28/30], Step [200/938], Loss: 0.0443\n",
      "Epoch [28/30], Step [300/938], Loss: 0.1216\n",
      "Epoch [28/30], Step [400/938], Loss: 0.0655\n",
      "Epoch [28/30], Step [500/938], Loss: 0.0933\n",
      "Epoch [28/30], Step [600/938], Loss: 0.1708\n",
      "Epoch [28/30], Step [700/938], Loss: 0.0313\n",
      "Epoch [28/30], Step [800/938], Loss: 0.0583\n",
      "Epoch [28/30], Step [900/938], Loss: 0.1059\n",
      "Train Accuracy: 98.16%\n",
      "Test Accuracy: 98.81%\n",
      "Test Loss: 0.0353\n",
      "Epoch [29/30], Step [100/938], Loss: 0.0628\n",
      "Epoch [29/30], Step [200/938], Loss: 0.0622\n",
      "Epoch [29/30], Step [300/938], Loss: 0.1525\n",
      "Epoch [29/30], Step [400/938], Loss: 0.0416\n",
      "Epoch [29/30], Step [500/938], Loss: 0.2492\n",
      "Epoch [29/30], Step [600/938], Loss: 0.0854\n",
      "Epoch [29/30], Step [700/938], Loss: 0.1190\n",
      "Epoch [29/30], Step [800/938], Loss: 0.0480\n",
      "Epoch [29/30], Step [900/938], Loss: 0.1402\n",
      "Train Accuracy: 98.12%\n",
      "Test Accuracy: 98.79%\n",
      "Test Loss: 0.0372\n",
      "Epoch [30/30], Step [100/938], Loss: 0.0398\n",
      "Epoch [30/30], Step [200/938], Loss: 0.1134\n",
      "Epoch [30/30], Step [300/938], Loss: 0.0311\n",
      "Epoch [30/30], Step [400/938], Loss: 0.0976\n",
      "Epoch [30/30], Step [500/938], Loss: 0.1057\n",
      "Epoch [30/30], Step [600/938], Loss: 0.0678\n",
      "Epoch [30/30], Step [700/938], Loss: 0.0268\n",
      "Epoch [30/30], Step [800/938], Loss: 0.1208\n",
      "Epoch [30/30], Step [900/938], Loss: 0.0926\n",
      "Train Accuracy: 98.12%\n",
      "Test Accuracy: 98.95%\n",
      "Test Loss: 0.0329\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from models.models import CNN, CNN_d\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "\n",
    "# Define the CNN + Dropout architecture with dropout and L2 regularization\n",
    "class CNN_d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_d, self).__init__()\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.25)  # Added dropout\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)  # Added dropout\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)  # Added dropout\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout2(x)  # Added dropout\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create an instance of the CNN with L2 regularization\n",
    "model = CNN_d().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "l2_lambda = 0.001  # L2 regularization lambda value\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=l2_lambda)\n",
    "\n",
    "# Initialize lists to store the train and test losses for each epoch\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # L2 regularization\n",
    "        l2_regularization = torch.tensor(0., device=device)\n",
    "        for param in model.parameters():\n",
    "            l2_regularization += torch.norm(param, 2)\n",
    "        loss += l2_lambda * l2_regularization\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    print(f'Train Accuracy: {(100 * correct / total):.2f}%')\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    # Print test accuracy at the end of each epoch\n",
    "    test_accuracy = (100 * correct / total)\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd5c986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 977    0    0    0    0    0    1    1    1    0]\n",
      " [   0 1127    1    2    1    1    1    1    1    0]\n",
      " [   2    0 1017    5    0    1    1    5    1    0]\n",
      " [   0    0    1 1006    0    1    0    0    2    0]\n",
      " [   0    0    0    0  972    0    3    0    3    4]\n",
      " [   2    0    0    7    0  875    4    1    2    1]\n",
      " [   3    2    0    0    1    2  949    0    1    0]\n",
      " [   0    3    4    3    0    1    0 1015    1    1]\n",
      " [   1    0    1    1    0    0    2    2  964    3]\n",
      " [   1    0    0    0    4    1    0    3    7  993]]\n"
     ]
    }
   ],
   "source": [
    "# Plot the train and test losses for each epoch\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a63bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
