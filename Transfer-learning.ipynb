{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecddf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32fc466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a93486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (ResNet18)\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 10)  # Replace the fully connected layer for 10 classes\n",
    "\n",
    "# Allow the freezed pre-trained layers' parameters to be updated\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e2ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/938], Loss: 0.6549\n",
      "Epoch [1/20], Step [200/938], Loss: 0.3399\n",
      "Epoch [1/20], Step [300/938], Loss: 0.3221\n",
      "Epoch [1/20], Step [400/938], Loss: 0.2017\n",
      "Epoch [1/20], Step [500/938], Loss: 0.2142\n",
      "Epoch [1/20], Step [600/938], Loss: 0.2029\n",
      "Epoch [1/20], Step [700/938], Loss: 0.2847\n",
      "Epoch [1/20], Step [800/938], Loss: 0.2688\n",
      "Epoch [1/20], Step [900/938], Loss: 0.1847\n",
      "Train Accuracy: 90.48%\n",
      "Epoch [2/20], Step [100/938], Loss: 0.2465\n",
      "Epoch [2/20], Step [200/938], Loss: 0.1310\n",
      "Epoch [2/20], Step [300/938], Loss: 0.1926\n",
      "Epoch [2/20], Step [400/938], Loss: 0.1413\n",
      "Epoch [2/20], Step [500/938], Loss: 0.2404\n",
      "Epoch [2/20], Step [600/938], Loss: 0.2171\n",
      "Epoch [2/20], Step [700/938], Loss: 0.1380\n",
      "Epoch [2/20], Step [800/938], Loss: 0.2061\n",
      "Epoch [2/20], Step [900/938], Loss: 0.1456\n",
      "Train Accuracy: 95.13%\n",
      "Epoch [3/20], Step [100/938], Loss: 0.1579\n",
      "Epoch [3/20], Step [200/938], Loss: 0.2035\n",
      "Epoch [3/20], Step [300/938], Loss: 0.1083\n",
      "Epoch [3/20], Step [400/938], Loss: 0.1291\n",
      "Epoch [3/20], Step [500/938], Loss: 0.2596\n",
      "Epoch [3/20], Step [600/938], Loss: 0.0529\n",
      "Epoch [3/20], Step [700/938], Loss: 0.1416\n",
      "Epoch [3/20], Step [800/938], Loss: 0.0903\n",
      "Epoch [3/20], Step [900/938], Loss: 0.0713\n",
      "Train Accuracy: 95.73%\n",
      "Epoch [4/20], Step [100/938], Loss: 0.2196\n",
      "Epoch [4/20], Step [200/938], Loss: 0.2408\n",
      "Epoch [4/20], Step [300/938], Loss: 0.1417\n",
      "Epoch [4/20], Step [400/938], Loss: 0.2144\n",
      "Epoch [4/20], Step [500/938], Loss: 0.2842\n",
      "Epoch [4/20], Step [600/938], Loss: 0.1740\n",
      "Epoch [4/20], Step [700/938], Loss: 0.0653\n",
      "Epoch [4/20], Step [800/938], Loss: 0.2227\n",
      "Epoch [4/20], Step [900/938], Loss: 0.1150\n",
      "Train Accuracy: 96.06%\n",
      "Epoch [5/20], Step [100/938], Loss: 0.1495\n",
      "Epoch [5/20], Step [200/938], Loss: 0.1433\n",
      "Epoch [5/20], Step [300/938], Loss: 0.1483\n",
      "Epoch [5/20], Step [400/938], Loss: 0.0741\n",
      "Epoch [5/20], Step [500/938], Loss: 0.0549\n",
      "Epoch [5/20], Step [600/938], Loss: 0.0807\n",
      "Epoch [5/20], Step [700/938], Loss: 0.3113\n",
      "Epoch [5/20], Step [800/938], Loss: 0.0715\n",
      "Epoch [5/20], Step [900/938], Loss: 0.1616\n",
      "Train Accuracy: 96.34%\n",
      "Epoch [6/20], Step [100/938], Loss: 0.1382\n",
      "Epoch [6/20], Step [200/938], Loss: 0.1095\n",
      "Epoch [6/20], Step [300/938], Loss: 0.1482\n",
      "Epoch [6/20], Step [400/938], Loss: 0.0660\n",
      "Epoch [6/20], Step [500/938], Loss: 0.0217\n",
      "Epoch [6/20], Step [600/938], Loss: 0.2237\n",
      "Epoch [6/20], Step [700/938], Loss: 0.2157\n",
      "Epoch [6/20], Step [800/938], Loss: 0.0644\n",
      "Epoch [6/20], Step [900/938], Loss: 0.1461\n",
      "Train Accuracy: 96.48%\n",
      "Epoch [7/20], Step [100/938], Loss: 0.0598\n",
      "Epoch [7/20], Step [200/938], Loss: 0.1845\n",
      "Epoch [7/20], Step [300/938], Loss: 0.1378\n",
      "Epoch [7/20], Step [400/938], Loss: 0.0615\n",
      "Epoch [7/20], Step [500/938], Loss: 0.0947\n",
      "Epoch [7/20], Step [600/938], Loss: 0.0158\n",
      "Epoch [7/20], Step [700/938], Loss: 0.0199\n",
      "Epoch [7/20], Step [800/938], Loss: 0.2150\n",
      "Epoch [7/20], Step [900/938], Loss: 0.1151\n",
      "Train Accuracy: 96.59%\n",
      "Epoch [8/20], Step [100/938], Loss: 0.1075\n",
      "Epoch [8/20], Step [200/938], Loss: 0.0429\n",
      "Epoch [8/20], Step [300/938], Loss: 0.1574\n",
      "Epoch [8/20], Step [400/938], Loss: 0.1089\n",
      "Epoch [8/20], Step [500/938], Loss: 0.1341\n",
      "Epoch [8/20], Step [600/938], Loss: 0.1398\n",
      "Epoch [8/20], Step [700/938], Loss: 0.0506\n",
      "Epoch [8/20], Step [800/938], Loss: 0.0572\n",
      "Epoch [8/20], Step [900/938], Loss: 0.1102\n",
      "Train Accuracy: 96.84%\n",
      "Epoch [9/20], Step [100/938], Loss: 0.0660\n",
      "Epoch [9/20], Step [200/938], Loss: 0.0913\n",
      "Epoch [9/20], Step [300/938], Loss: 0.0662\n",
      "Epoch [9/20], Step [400/938], Loss: 0.1508\n",
      "Epoch [9/20], Step [500/938], Loss: 0.0610\n",
      "Epoch [9/20], Step [600/938], Loss: 0.0638\n",
      "Epoch [9/20], Step [700/938], Loss: 0.1130\n",
      "Epoch [9/20], Step [800/938], Loss: 0.0272\n",
      "Epoch [9/20], Step [900/938], Loss: 0.1039\n",
      "Train Accuracy: 96.87%\n",
      "Epoch [10/20], Step [100/938], Loss: 0.1346\n",
      "Epoch [10/20], Step [200/938], Loss: 0.0626\n",
      "Epoch [10/20], Step [300/938], Loss: 0.1078\n",
      "Epoch [10/20], Step [400/938], Loss: 0.1057\n",
      "Epoch [10/20], Step [500/938], Loss: 0.0246\n",
      "Epoch [10/20], Step [600/938], Loss: 0.1699\n",
      "Epoch [10/20], Step [700/938], Loss: 0.1109\n",
      "Epoch [10/20], Step [800/938], Loss: 0.0759\n",
      "Epoch [10/20], Step [900/938], Loss: 0.0929\n",
      "Train Accuracy: 96.86%\n",
      "Epoch [11/20], Step [100/938], Loss: 0.1653\n",
      "Epoch [11/20], Step [200/938], Loss: 0.0543\n",
      "Epoch [11/20], Step [300/938], Loss: 0.0815\n",
      "Epoch [11/20], Step [400/938], Loss: 0.0863\n",
      "Epoch [11/20], Step [500/938], Loss: 0.1935\n",
      "Epoch [11/20], Step [600/938], Loss: 0.1143\n",
      "Epoch [11/20], Step [700/938], Loss: 0.0680\n",
      "Epoch [11/20], Step [800/938], Loss: 0.0799\n",
      "Epoch [11/20], Step [900/938], Loss: 0.0107\n",
      "Train Accuracy: 96.98%\n",
      "Epoch [12/20], Step [100/938], Loss: 0.0769\n",
      "Epoch [12/20], Step [200/938], Loss: 0.1848\n",
      "Epoch [12/20], Step [300/938], Loss: 0.1186\n",
      "Epoch [12/20], Step [400/938], Loss: 0.1570\n",
      "Epoch [12/20], Step [500/938], Loss: 0.1711\n",
      "Epoch [12/20], Step [600/938], Loss: 0.0546\n",
      "Epoch [12/20], Step [700/938], Loss: 0.0440\n",
      "Epoch [12/20], Step [800/938], Loss: 0.0377\n",
      "Epoch [12/20], Step [900/938], Loss: 0.1631\n",
      "Train Accuracy: 97.00%\n",
      "Epoch [13/20], Step [100/938], Loss: 0.0716\n",
      "Epoch [13/20], Step [200/938], Loss: 0.0904\n",
      "Epoch [13/20], Step [300/938], Loss: 0.0347\n",
      "Epoch [13/20], Step [400/938], Loss: 0.0289\n",
      "Epoch [13/20], Step [500/938], Loss: 0.0726\n",
      "Epoch [13/20], Step [600/938], Loss: 0.1377\n",
      "Epoch [13/20], Step [700/938], Loss: 0.0340\n",
      "Epoch [13/20], Step [800/938], Loss: 0.0437\n",
      "Epoch [13/20], Step [900/938], Loss: 0.1951\n",
      "Train Accuracy: 97.12%\n",
      "Epoch [14/20], Step [100/938], Loss: 0.0704\n",
      "Epoch [14/20], Step [200/938], Loss: 0.1309\n",
      "Epoch [14/20], Step [300/938], Loss: 0.0900\n",
      "Epoch [14/20], Step [400/938], Loss: 0.0729\n",
      "Epoch [14/20], Step [500/938], Loss: 0.0673\n",
      "Epoch [14/20], Step [600/938], Loss: 0.0686\n",
      "Epoch [14/20], Step [700/938], Loss: 0.0991\n",
      "Epoch [14/20], Step [800/938], Loss: 0.0339\n",
      "Epoch [14/20], Step [900/938], Loss: 0.0496\n",
      "Train Accuracy: 97.08%\n",
      "Epoch [15/20], Step [100/938], Loss: 0.0175\n",
      "Epoch [15/20], Step [200/938], Loss: 0.1782\n",
      "Epoch [15/20], Step [300/938], Loss: 0.1982\n",
      "Epoch [15/20], Step [400/938], Loss: 0.0499\n",
      "Epoch [15/20], Step [500/938], Loss: 0.0748\n",
      "Epoch [15/20], Step [600/938], Loss: 0.0886\n",
      "Epoch [15/20], Step [700/938], Loss: 0.0471\n",
      "Epoch [15/20], Step [800/938], Loss: 0.1230\n",
      "Epoch [15/20], Step [900/938], Loss: 0.0456\n",
      "Train Accuracy: 97.11%\n",
      "Epoch [16/20], Step [100/938], Loss: 0.0511\n",
      "Epoch [16/20], Step [200/938], Loss: 0.3478\n",
      "Epoch [16/20], Step [300/938], Loss: 0.0307\n",
      "Epoch [16/20], Step [400/938], Loss: 0.0184\n",
      "Epoch [16/20], Step [500/938], Loss: 0.1206\n",
      "Epoch [16/20], Step [600/938], Loss: 0.1246\n",
      "Epoch [16/20], Step [700/938], Loss: 0.0574\n",
      "Epoch [16/20], Step [800/938], Loss: 0.0423\n",
      "Epoch [16/20], Step [900/938], Loss: 0.0522\n",
      "Train Accuracy: 97.26%\n",
      "Epoch [17/20], Step [100/938], Loss: 0.0294\n",
      "Epoch [17/20], Step [200/938], Loss: 0.0583\n",
      "Epoch [17/20], Step [300/938], Loss: 0.1502\n",
      "Epoch [17/20], Step [400/938], Loss: 0.0405\n",
      "Epoch [17/20], Step [500/938], Loss: 0.0535\n",
      "Epoch [17/20], Step [600/938], Loss: 0.0388\n",
      "Epoch [17/20], Step [700/938], Loss: 0.0895\n",
      "Epoch [17/20], Step [800/938], Loss: 0.0845\n",
      "Epoch [17/20], Step [900/938], Loss: 0.1454\n",
      "Train Accuracy: 97.30%\n",
      "Epoch [18/20], Step [100/938], Loss: 0.0247\n",
      "Epoch [18/20], Step [200/938], Loss: 0.0772\n",
      "Epoch [18/20], Step [300/938], Loss: 0.0702\n",
      "Epoch [18/20], Step [400/938], Loss: 0.0656\n",
      "Epoch [18/20], Step [500/938], Loss: 0.0850\n",
      "Epoch [18/20], Step [600/938], Loss: 0.0520\n",
      "Epoch [18/20], Step [700/938], Loss: 0.0635\n",
      "Epoch [18/20], Step [800/938], Loss: 0.0209\n",
      "Epoch [18/20], Step [900/938], Loss: 0.0288\n",
      "Train Accuracy: 97.29%\n",
      "Epoch [19/20], Step [100/938], Loss: 0.1108\n",
      "Epoch [19/20], Step [200/938], Loss: 0.0812\n",
      "Epoch [19/20], Step [300/938], Loss: 0.0824\n",
      "Epoch [19/20], Step [400/938], Loss: 0.0730\n",
      "Epoch [19/20], Step [500/938], Loss: 0.1006\n",
      "Epoch [19/20], Step [600/938], Loss: 0.0507\n",
      "Epoch [19/20], Step [700/938], Loss: 0.0427\n",
      "Epoch [19/20], Step [800/938], Loss: 0.0923\n",
      "Epoch [19/20], Step [900/938], Loss: 0.0723\n",
      "Train Accuracy: 97.28%\n",
      "Epoch [20/20], Step [100/938], Loss: 0.1303\n",
      "Epoch [20/20], Step [200/938], Loss: 0.1057\n",
      "Epoch [20/20], Step [300/938], Loss: 0.0283\n",
      "Epoch [20/20], Step [400/938], Loss: 0.0336\n",
      "Epoch [20/20], Step [500/938], Loss: 0.1047\n",
      "Epoch [20/20], Step [600/938], Loss: 0.0258\n",
      "Epoch [20/20], Step [700/938], Loss: 0.0147\n",
      "Epoch [20/20], Step [800/938], Loss: 0.1119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Step [900/938], Loss: 0.0610\n",
      "Train Accuracy: 97.40%\n",
      "Test Accuracy: 97.07%\n",
      "Test Loss: 0.0927\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    print(f'Train Accuracy: {(100 * correct / total):.2f}%')\n",
    "\n",
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = (100 * correct / total)\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
