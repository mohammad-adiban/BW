{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2215a934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [100/938], Loss: 0.5609\n",
      "Epoch [1/30], Step [200/938], Loss: 0.3167\n",
      "Epoch [1/30], Step [300/938], Loss: 0.3241\n",
      "Epoch [1/30], Step [400/938], Loss: 0.3874\n",
      "Epoch [1/30], Step [500/938], Loss: 0.4644\n",
      "Epoch [1/30], Step [600/938], Loss: 0.1524\n",
      "Epoch [1/30], Step [700/938], Loss: 0.3031\n",
      "Epoch [1/30], Step [800/938], Loss: 0.2918\n",
      "Epoch [1/30], Step [900/938], Loss: 0.1454\n",
      "Train Accuracy: 89.40%\n",
      "Test Accuracy: 98.12%\n",
      "Test Loss: 0.0603\n",
      "Epoch [2/30], Step [100/938], Loss: 0.0650\n",
      "Epoch [2/30], Step [200/938], Loss: 0.0577\n",
      "Epoch [2/30], Step [300/938], Loss: 0.0632\n",
      "Epoch [2/30], Step [400/938], Loss: 0.0596\n",
      "Epoch [2/30], Step [500/938], Loss: 0.1123\n",
      "Epoch [2/30], Step [600/938], Loss: 0.1244\n",
      "Epoch [2/30], Step [700/938], Loss: 0.0670\n",
      "Epoch [2/30], Step [800/938], Loss: 0.2649\n",
      "Epoch [2/30], Step [900/938], Loss: 0.0411\n",
      "Train Accuracy: 95.80%\n",
      "Test Accuracy: 98.59%\n",
      "Test Loss: 0.0442\n",
      "Epoch [3/30], Step [100/938], Loss: 0.0776\n",
      "Epoch [3/30], Step [200/938], Loss: 0.1599\n",
      "Epoch [3/30], Step [300/938], Loss: 0.3054\n",
      "Epoch [3/30], Step [400/938], Loss: 0.0271\n",
      "Epoch [3/30], Step [500/938], Loss: 0.0440\n",
      "Epoch [3/30], Step [600/938], Loss: 0.0319\n",
      "Epoch [3/30], Step [700/938], Loss: 0.1683\n",
      "Epoch [3/30], Step [800/938], Loss: 0.2078\n",
      "Epoch [3/30], Step [900/938], Loss: 0.0911\n",
      "Train Accuracy: 96.87%\n",
      "Test Accuracy: 98.84%\n",
      "Test Loss: 0.0374\n",
      "Epoch [4/30], Step [100/938], Loss: 0.0287\n",
      "Epoch [4/30], Step [200/938], Loss: 0.0142\n",
      "Epoch [4/30], Step [300/938], Loss: 0.2092\n",
      "Epoch [4/30], Step [400/938], Loss: 0.4192\n",
      "Epoch [4/30], Step [500/938], Loss: 0.1064\n",
      "Epoch [4/30], Step [600/938], Loss: 0.0467\n",
      "Epoch [4/30], Step [700/938], Loss: 0.0633\n",
      "Epoch [4/30], Step [800/938], Loss: 0.1201\n",
      "Epoch [4/30], Step [900/938], Loss: 0.0592\n",
      "Train Accuracy: 97.34%\n",
      "Test Accuracy: 98.81%\n",
      "Test Loss: 0.0343\n",
      "Epoch [5/30], Step [100/938], Loss: 0.1148\n",
      "Epoch [5/30], Step [200/938], Loss: 0.0258\n",
      "Epoch [5/30], Step [300/938], Loss: 0.1258\n",
      "Epoch [5/30], Step [400/938], Loss: 0.0387\n",
      "Epoch [5/30], Step [500/938], Loss: 0.0361\n",
      "Epoch [5/30], Step [600/938], Loss: 0.0775\n",
      "Epoch [5/30], Step [700/938], Loss: 0.0119\n",
      "Epoch [5/30], Step [800/938], Loss: 0.1616\n",
      "Epoch [5/30], Step [900/938], Loss: 0.0336\n",
      "Train Accuracy: 97.78%\n",
      "Test Accuracy: 98.85%\n",
      "Test Loss: 0.0329\n",
      "Epoch [6/30], Step [100/938], Loss: 0.2276\n",
      "Epoch [6/30], Step [200/938], Loss: 0.0795\n",
      "Epoch [6/30], Step [300/938], Loss: 0.0724\n",
      "Epoch [6/30], Step [400/938], Loss: 0.0191\n",
      "Epoch [6/30], Step [500/938], Loss: 0.1600\n",
      "Epoch [6/30], Step [600/938], Loss: 0.1274\n",
      "Epoch [6/30], Step [700/938], Loss: 0.0886\n",
      "Epoch [6/30], Step [800/938], Loss: 0.0991\n",
      "Epoch [6/30], Step [900/938], Loss: 0.0185\n",
      "Train Accuracy: 97.83%\n",
      "Test Accuracy: 99.06%\n",
      "Test Loss: 0.0311\n",
      "Epoch [7/30], Step [100/938], Loss: 0.1219\n",
      "Epoch [7/30], Step [200/938], Loss: 0.0314\n",
      "Epoch [7/30], Step [300/938], Loss: 0.0891\n",
      "Epoch [7/30], Step [400/938], Loss: 0.1295\n",
      "Epoch [7/30], Step [500/938], Loss: 0.0494\n",
      "Epoch [7/30], Step [600/938], Loss: 0.0274\n",
      "Epoch [7/30], Step [700/938], Loss: 0.0456\n",
      "Epoch [7/30], Step [800/938], Loss: 0.0089\n",
      "Epoch [7/30], Step [900/938], Loss: 0.0635\n",
      "Train Accuracy: 98.06%\n",
      "Test Accuracy: 99.01%\n",
      "Test Loss: 0.0323\n",
      "Epoch [8/30], Step [100/938], Loss: 0.0221\n",
      "Epoch [8/30], Step [200/938], Loss: 0.0067\n",
      "Epoch [8/30], Step [300/938], Loss: 0.0205\n",
      "Epoch [8/30], Step [400/938], Loss: 0.0221\n",
      "Epoch [8/30], Step [500/938], Loss: 0.1571\n",
      "Epoch [8/30], Step [600/938], Loss: 0.0473\n",
      "Epoch [8/30], Step [700/938], Loss: 0.2990\n",
      "Epoch [8/30], Step [800/938], Loss: 0.0631\n",
      "Epoch [8/30], Step [900/938], Loss: 0.1288\n",
      "Train Accuracy: 98.24%\n",
      "Test Accuracy: 99.10%\n",
      "Test Loss: 0.0308\n",
      "Epoch [9/30], Step [100/938], Loss: 0.0143\n",
      "Epoch [9/30], Step [200/938], Loss: 0.0476\n",
      "Epoch [9/30], Step [300/938], Loss: 0.0055\n",
      "Epoch [9/30], Step [400/938], Loss: 0.0572\n",
      "Epoch [9/30], Step [500/938], Loss: 0.0073\n",
      "Epoch [9/30], Step [600/938], Loss: 0.0193\n",
      "Epoch [9/30], Step [700/938], Loss: 0.0729\n",
      "Epoch [9/30], Step [800/938], Loss: 0.1561\n",
      "Epoch [9/30], Step [900/938], Loss: 0.0338\n",
      "Train Accuracy: 98.41%\n",
      "Test Accuracy: 99.01%\n",
      "Test Loss: 0.0312\n",
      "Epoch [10/30], Step [100/938], Loss: 0.0601\n",
      "Epoch [10/30], Step [200/938], Loss: 0.0068\n",
      "Epoch [10/30], Step [300/938], Loss: 0.0197\n",
      "Epoch [10/30], Step [400/938], Loss: 0.1050\n",
      "Epoch [10/30], Step [500/938], Loss: 0.0440\n",
      "Epoch [10/30], Step [600/938], Loss: 0.0432\n",
      "Epoch [10/30], Step [700/938], Loss: 0.0511\n",
      "Epoch [10/30], Step [800/938], Loss: 0.1018\n",
      "Epoch [10/30], Step [900/938], Loss: 0.0670\n",
      "Train Accuracy: 98.46%\n",
      "Test Accuracy: 99.12%\n",
      "Test Loss: 0.0323\n",
      "Epoch [11/30], Step [100/938], Loss: 0.0090\n",
      "Epoch [11/30], Step [200/938], Loss: 0.1036\n",
      "Epoch [11/30], Step [300/938], Loss: 0.0058\n",
      "Epoch [11/30], Step [400/938], Loss: 0.0274\n",
      "Epoch [11/30], Step [500/938], Loss: 0.0567\n",
      "Epoch [11/30], Step [600/938], Loss: 0.0381\n",
      "Epoch [11/30], Step [700/938], Loss: 0.0221\n",
      "Epoch [11/30], Step [800/938], Loss: 0.0289\n",
      "Epoch [11/30], Step [900/938], Loss: 0.0475\n",
      "Train Accuracy: 98.46%\n",
      "Test Accuracy: 99.04%\n",
      "Test Loss: 0.0308\n",
      "Epoch [12/30], Step [100/938], Loss: 0.1946\n",
      "Epoch [12/30], Step [200/938], Loss: 0.0087\n",
      "Epoch [12/30], Step [300/938], Loss: 0.0310\n",
      "Epoch [12/30], Step [400/938], Loss: 0.0097\n",
      "Epoch [12/30], Step [500/938], Loss: 0.0023\n",
      "Epoch [12/30], Step [600/938], Loss: 0.0432\n",
      "Epoch [12/30], Step [700/938], Loss: 0.0401\n",
      "Epoch [12/30], Step [800/938], Loss: 0.0369\n",
      "Epoch [12/30], Step [900/938], Loss: 0.0240\n",
      "Train Accuracy: 98.61%\n",
      "Test Accuracy: 99.08%\n",
      "Test Loss: 0.0312\n",
      "Epoch [13/30], Step [100/938], Loss: 0.0124\n",
      "Epoch [13/30], Step [200/938], Loss: 0.0249\n",
      "Epoch [13/30], Step [300/938], Loss: 0.0185\n",
      "Epoch [13/30], Step [400/938], Loss: 0.0075\n",
      "Epoch [13/30], Step [500/938], Loss: 0.0359\n",
      "Epoch [13/30], Step [600/938], Loss: 0.0100\n",
      "Epoch [13/30], Step [700/938], Loss: 0.0281\n",
      "Epoch [13/30], Step [800/938], Loss: 0.0044\n",
      "Epoch [13/30], Step [900/938], Loss: 0.0278\n",
      "Train Accuracy: 98.62%\n",
      "Test Accuracy: 99.09%\n",
      "Test Loss: 0.0342\n",
      "Epoch [14/30], Step [100/938], Loss: 0.0308\n",
      "Epoch [14/30], Step [200/938], Loss: 0.0285\n",
      "Epoch [14/30], Step [300/938], Loss: 0.0512\n",
      "Epoch [14/30], Step [400/938], Loss: 0.0117\n",
      "Epoch [14/30], Step [500/938], Loss: 0.0322\n",
      "Epoch [14/30], Step [600/938], Loss: 0.0538\n",
      "Epoch [14/30], Step [700/938], Loss: 0.0521\n",
      "Epoch [14/30], Step [800/938], Loss: 0.0199\n",
      "Epoch [14/30], Step [900/938], Loss: 0.0009\n",
      "Train Accuracy: 98.70%\n",
      "Test Accuracy: 99.15%\n",
      "Test Loss: 0.0305\n",
      "Epoch [15/30], Step [100/938], Loss: 0.0232\n",
      "Epoch [15/30], Step [200/938], Loss: 0.0380\n",
      "Epoch [15/30], Step [300/938], Loss: 0.1478\n",
      "Epoch [15/30], Step [400/938], Loss: 0.0157\n",
      "Epoch [15/30], Step [500/938], Loss: 0.0165\n",
      "Epoch [15/30], Step [600/938], Loss: 0.0397\n",
      "Epoch [15/30], Step [700/938], Loss: 0.0403\n",
      "Epoch [15/30], Step [800/938], Loss: 0.0204\n",
      "Epoch [15/30], Step [900/938], Loss: 0.0458\n",
      "Train Accuracy: 98.80%\n",
      "Test Accuracy: 99.10%\n",
      "Test Loss: 0.0357\n",
      "Epoch [16/30], Step [100/938], Loss: 0.0068\n",
      "Epoch [16/30], Step [200/938], Loss: 0.0029\n",
      "Epoch [16/30], Step [300/938], Loss: 0.0614\n",
      "Epoch [16/30], Step [400/938], Loss: 0.1451\n",
      "Epoch [16/30], Step [500/938], Loss: 0.0380\n",
      "Epoch [16/30], Step [600/938], Loss: 0.1452\n",
      "Epoch [16/30], Step [700/938], Loss: 0.0011\n",
      "Epoch [16/30], Step [800/938], Loss: 0.0327\n",
      "Epoch [16/30], Step [900/938], Loss: 0.1077\n",
      "Train Accuracy: 98.78%\n",
      "Test Accuracy: 99.18%\n",
      "Test Loss: 0.0341\n",
      "Epoch [17/30], Step [100/938], Loss: 0.0578\n",
      "Epoch [17/30], Step [200/938], Loss: 0.0003\n",
      "Epoch [17/30], Step [300/938], Loss: 0.0205\n",
      "Epoch [17/30], Step [400/938], Loss: 0.0640\n",
      "Epoch [17/30], Step [500/938], Loss: 0.0188\n",
      "Epoch [17/30], Step [600/938], Loss: 0.0091\n",
      "Epoch [17/30], Step [700/938], Loss: 0.0008\n",
      "Epoch [17/30], Step [800/938], Loss: 0.0009\n",
      "Epoch [17/30], Step [900/938], Loss: 0.0490\n",
      "Train Accuracy: 98.79%\n",
      "Test Accuracy: 99.08%\n",
      "Test Loss: 0.0327\n",
      "Epoch [18/30], Step [100/938], Loss: 0.0242\n",
      "Epoch [18/30], Step [200/938], Loss: 0.0226\n",
      "Epoch [18/30], Step [300/938], Loss: 0.0148\n",
      "Epoch [18/30], Step [400/938], Loss: 0.0081\n",
      "Epoch [18/30], Step [500/938], Loss: 0.0081\n",
      "Epoch [18/30], Step [600/938], Loss: 0.1177\n",
      "Epoch [18/30], Step [700/938], Loss: 0.0262\n",
      "Epoch [18/30], Step [800/938], Loss: 0.0493\n",
      "Epoch [18/30], Step [900/938], Loss: 0.0063\n",
      "Train Accuracy: 98.83%\n",
      "Test Accuracy: 99.13%\n",
      "Test Loss: 0.0317\n",
      "Epoch [19/30], Step [100/938], Loss: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Step [200/938], Loss: 0.0032\n",
      "Epoch [19/30], Step [300/938], Loss: 0.0630\n",
      "Epoch [19/30], Step [400/938], Loss: 0.0041\n",
      "Epoch [19/30], Step [500/938], Loss: 0.0169\n",
      "Epoch [19/30], Step [600/938], Loss: 0.0098\n",
      "Epoch [19/30], Step [700/938], Loss: 0.0235\n",
      "Epoch [19/30], Step [800/938], Loss: 0.0225\n",
      "Epoch [19/30], Step [900/938], Loss: 0.0098\n",
      "Train Accuracy: 98.91%\n",
      "Test Accuracy: 99.15%\n",
      "Test Loss: 0.0353\n",
      "Epoch [20/30], Step [100/938], Loss: 0.0073\n",
      "Epoch [20/30], Step [200/938], Loss: 0.0719\n",
      "Epoch [20/30], Step [300/938], Loss: 0.1390\n",
      "Epoch [20/30], Step [400/938], Loss: 0.0717\n",
      "Epoch [20/30], Step [500/938], Loss: 0.0226\n",
      "Epoch [20/30], Step [600/938], Loss: 0.0133\n",
      "Epoch [20/30], Step [700/938], Loss: 0.0011\n",
      "Epoch [20/30], Step [800/938], Loss: 0.0704\n",
      "Epoch [20/30], Step [900/938], Loss: 0.0243\n",
      "Train Accuracy: 98.99%\n",
      "Test Accuracy: 99.08%\n",
      "Test Loss: 0.0366\n",
      "Epoch [21/30], Step [100/938], Loss: 0.0517\n",
      "Epoch [21/30], Step [200/938], Loss: 0.0666\n",
      "Epoch [21/30], Step [300/938], Loss: 0.0131\n",
      "Epoch [21/30], Step [400/938], Loss: 0.0055\n",
      "Epoch [21/30], Step [500/938], Loss: 0.0085\n",
      "Epoch [21/30], Step [600/938], Loss: 0.0093\n",
      "Epoch [21/30], Step [700/938], Loss: 0.1603\n",
      "Epoch [21/30], Step [800/938], Loss: 0.0155\n",
      "Epoch [21/30], Step [900/938], Loss: 0.0136\n",
      "Train Accuracy: 98.97%\n",
      "Test Accuracy: 99.15%\n",
      "Test Loss: 0.0346\n",
      "Epoch [22/30], Step [100/938], Loss: 0.0299\n",
      "Epoch [22/30], Step [200/938], Loss: 0.0107\n",
      "Epoch [22/30], Step [300/938], Loss: 0.0116\n",
      "Epoch [22/30], Step [400/938], Loss: 0.0423\n",
      "Epoch [22/30], Step [500/938], Loss: 0.1049\n",
      "Epoch [22/30], Step [600/938], Loss: 0.0863\n",
      "Epoch [22/30], Step [700/938], Loss: 0.0257\n",
      "Epoch [22/30], Step [800/938], Loss: 0.0098\n",
      "Epoch [22/30], Step [900/938], Loss: 0.0062\n",
      "Train Accuracy: 99.02%\n",
      "Test Accuracy: 99.04%\n",
      "Test Loss: 0.0371\n",
      "Epoch [23/30], Step [100/938], Loss: 0.0113\n",
      "Epoch [23/30], Step [200/938], Loss: 0.0700\n",
      "Epoch [23/30], Step [300/938], Loss: 0.0035\n",
      "Epoch [23/30], Step [400/938], Loss: 0.0003\n",
      "Epoch [23/30], Step [500/938], Loss: 0.0902\n",
      "Epoch [23/30], Step [600/938], Loss: 0.0054\n",
      "Epoch [23/30], Step [700/938], Loss: 0.0880\n",
      "Epoch [23/30], Step [800/938], Loss: 0.0124\n",
      "Epoch [23/30], Step [900/938], Loss: 0.0149\n",
      "Train Accuracy: 99.04%\n",
      "Test Accuracy: 99.14%\n",
      "Test Loss: 0.0374\n",
      "Epoch [24/30], Step [100/938], Loss: 0.0023\n",
      "Epoch [24/30], Step [200/938], Loss: 0.0039\n",
      "Epoch [24/30], Step [300/938], Loss: 0.0250\n",
      "Epoch [24/30], Step [400/938], Loss: 0.0019\n",
      "Epoch [24/30], Step [500/938], Loss: 0.0199\n",
      "Epoch [24/30], Step [600/938], Loss: 0.0735\n",
      "Epoch [24/30], Step [700/938], Loss: 0.1252\n",
      "Epoch [24/30], Step [800/938], Loss: 0.0080\n",
      "Epoch [24/30], Step [900/938], Loss: 0.0117\n",
      "Train Accuracy: 99.02%\n",
      "Test Accuracy: 99.10%\n",
      "Test Loss: 0.0380\n",
      "Epoch [25/30], Step [100/938], Loss: 0.0244\n",
      "Epoch [25/30], Step [200/938], Loss: 0.0128\n",
      "Epoch [25/30], Step [300/938], Loss: 0.0019\n",
      "Epoch [25/30], Step [400/938], Loss: 0.0465\n",
      "Epoch [25/30], Step [500/938], Loss: 0.0012\n",
      "Epoch [25/30], Step [600/938], Loss: 0.0379\n",
      "Epoch [25/30], Step [700/938], Loss: 0.0191\n",
      "Epoch [25/30], Step [800/938], Loss: 0.0102\n",
      "Epoch [25/30], Step [900/938], Loss: 0.0101\n",
      "Train Accuracy: 99.01%\n",
      "Test Accuracy: 99.10%\n",
      "Test Loss: 0.0375\n",
      "Epoch [26/30], Step [100/938], Loss: 0.0021\n",
      "Epoch [26/30], Step [200/938], Loss: 0.0011\n",
      "Epoch [26/30], Step [300/938], Loss: 0.0674\n",
      "Epoch [26/30], Step [400/938], Loss: 0.0002\n",
      "Epoch [26/30], Step [500/938], Loss: 0.0092\n",
      "Epoch [26/30], Step [600/938], Loss: 0.0201\n",
      "Epoch [26/30], Step [700/938], Loss: 0.0058\n",
      "Epoch [26/30], Step [800/938], Loss: 0.0108\n",
      "Epoch [26/30], Step [900/938], Loss: 0.0007\n",
      "Train Accuracy: 99.08%\n",
      "Test Accuracy: 99.18%\n",
      "Test Loss: 0.0330\n",
      "Epoch [27/30], Step [100/938], Loss: 0.0158\n",
      "Epoch [27/30], Step [200/938], Loss: 0.0382\n",
      "Epoch [27/30], Step [300/938], Loss: 0.0007\n",
      "Epoch [27/30], Step [400/938], Loss: 0.0784\n",
      "Epoch [27/30], Step [500/938], Loss: 0.0109\n",
      "Epoch [27/30], Step [600/938], Loss: 0.0917\n",
      "Epoch [27/30], Step [700/938], Loss: 0.0031\n",
      "Epoch [27/30], Step [800/938], Loss: 0.0003\n",
      "Epoch [27/30], Step [900/938], Loss: 0.0041\n",
      "Train Accuracy: 99.05%\n",
      "Test Accuracy: 99.12%\n",
      "Test Loss: 0.0402\n",
      "Epoch [28/30], Step [100/938], Loss: 0.0058\n",
      "Epoch [28/30], Step [200/938], Loss: 0.0012\n",
      "Epoch [28/30], Step [300/938], Loss: 0.0017\n",
      "Epoch [28/30], Step [400/938], Loss: 0.0005\n",
      "Epoch [28/30], Step [500/938], Loss: 0.0002\n",
      "Epoch [28/30], Step [600/938], Loss: 0.0338\n",
      "Epoch [28/30], Step [700/938], Loss: 0.0005\n",
      "Epoch [28/30], Step [800/938], Loss: 0.0519\n",
      "Epoch [28/30], Step [900/938], Loss: 0.0182\n",
      "Train Accuracy: 99.08%\n",
      "Test Accuracy: 99.17%\n",
      "Test Loss: 0.0371\n",
      "Epoch [29/30], Step [100/938], Loss: 0.0077\n",
      "Epoch [29/30], Step [200/938], Loss: 0.0062\n",
      "Epoch [29/30], Step [300/938], Loss: 0.0006\n",
      "Epoch [29/30], Step [400/938], Loss: 0.0391\n",
      "Epoch [29/30], Step [500/938], Loss: 0.0867\n",
      "Epoch [29/30], Step [600/938], Loss: 0.1124\n",
      "Epoch [29/30], Step [700/938], Loss: 0.0007\n",
      "Epoch [29/30], Step [800/938], Loss: 0.0098\n",
      "Epoch [29/30], Step [900/938], Loss: 0.2444\n",
      "Train Accuracy: 99.17%\n",
      "Test Accuracy: 99.19%\n",
      "Test Loss: 0.0399\n",
      "Epoch [30/30], Step [100/938], Loss: 0.0236\n",
      "Epoch [30/30], Step [200/938], Loss: 0.0970\n",
      "Epoch [30/30], Step [300/938], Loss: 0.0206\n",
      "Epoch [30/30], Step [400/938], Loss: 0.0898\n",
      "Epoch [30/30], Step [500/938], Loss: 0.0569\n",
      "Epoch [30/30], Step [600/938], Loss: 0.0104\n",
      "Epoch [30/30], Step [700/938], Loss: 0.0351\n",
      "Epoch [30/30], Step [800/938], Loss: 0.0148\n",
      "Epoch [30/30], Step [900/938], Loss: 0.0157\n",
      "Train Accuracy: 99.09%\n",
      "Test Accuracy: 99.08%\n",
      "Test Loss: 0.0420\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwK0lEQVR4nO3dd3gd5Zn///etIx31brlJNi7YpriCsBMTQk8IJDiwKRBIzCb7ZclCTJZfIHWTLBu+F8nul4S2lE0M2ZQ1hISShYSQgIGE4kK3sXHB2DIusmSrd92/P2ZkHwtJSLaOj6TzeV3XXNPP3OMjz32e55l5xtwdERGR7lISHYCIiAxNShAiItIjJQgREemREoSIiPRICUJERHqkBCEiIj1KjeeHm9k5wM1ABPipu9/Ybf0VwJVAB1APXO7ua81sEvAmsD7c9AV3v6KvY40aNconTZo0uCcgIjLCrV69eo+7l/S0zuL1HISZRYC3gLOBCmAlcLG7r43ZJs/da8Pp84F/cvdzwgTxv+4+s7/HKy8v91WrVg3mKYiIjHhmttrdy3taF88qpvnARnff7O6twDJgUewGXckhlA3oqT0RkSEingmiFNgWM18RLjuImV1pZpuAHwFLYlZNNrOXzexpMzsljnGKiEgPEt5I7e63u/tU4OvAd8LFO4CJ7j4PuAb4tZnldd/XzC43s1VmtqqysvLIBS0ikgTi2Ui9HZgQM18WLuvNMuAOAHdvAVrC6dVhCWM6cFAjg7vfDdwNQRvEoEUuIgnX1tZGRUUFzc3NiQ5lRMjIyKCsrIy0tLR+7xPPBLESmGZmkwkSw0XA52I3MLNp7r4hnD0P2BAuLwGq3b3DzKYA04DNcYxVRIaYiooKcnNzmTRpEmaW6HCGNXenqqqKiooKJk+e3O/94pYg3L3dzK4CHie4zXWpu68xs+uBVe7+CHCVmZ0FtAF7gcXh7h8GrjezNqATuMLdq+MVq4gMPc3NzUoOg8TMKC4uZqBV8XF9DsLdHwMe67bsuzHTV/ey32+B38YzNhEZ+pQcBs+h/FsmvJE60Wqb2/jxE2/xyrZ9iQ5FRGRISfoE4Z1w8182sGqLarBE5ICqqirmzp3L3LlzGTt2LKWlpfvnW1tb+9x31apVLFmypM9tups0aRJ79uw5nJAHXVyrmIaDvMxUUlOMqoa+v3ARSS7FxcW88sorAHz/+98nJyeHr33ta/vXt7e3k5ra8yW0vLyc8vIeH04eVpK+BGFmFGZHqa5XghCRvl122WVcccUVLFiwgOuuu44VK1bwwQ9+kHnz5rFw4ULWrw+6j1u+fDkf//jHgSC5fPGLX+S0005jypQp3HLLLf0+3pYtWzjjjDOYPXs2Z555Jlu3bgXgN7/5DTNnzmTOnDl8+MMfBmDNmjXMnz+fuXPnMnv2bDZs2NDXR/dL0pcgAIqzoypBiAxh//r7Nax9t/b9NxyA48bn8b1PHD/g/SoqKnjuueeIRCLU1tby7LPPkpqayp///Ge+9a1v8dvfvvf+mnXr1vHUU09RV1fHjBkz+PKXv9yv5xG+8pWvsHjxYhYvXszSpUtZsmQJDz30ENdffz2PP/44paWl7Nu3D4A777yTq6++mksuuYTW1lY6OjoGfG7dKUEARdlRqhtaEh2GiAwDn/70p4lEIgDU1NSwePFiNmzYgJnR1tbW4z7nnXce6enppKenM3r0aHbt2kVZWdn7Huv555/nd7/7HQCf//znue666wA4+eSTueyyy/jMZz7DhRdeCMAHP/hBbrjhBioqKrjwwguZNm3aYZ+rEgRQnJPO6xX7Eh2GiPTiUH7px0t2dvb+6X/5l3/h9NNP58EHH2TLli2cdtppPe6Tnp6+fzoSidDe3n5YMdx55528+OKLPProo5x44omsXr2az33ucyxYsIBHH32Uc889l7vuuoszzjjjsI6T9G0QoComETk0NTU1lJYGfZDee++9g/75CxcuZNmyZQD86le/4pRTgn5LN23axIIFC7j++uspKSlh27ZtbN68mSlTprBkyRIWLVrEa6+9dtjHV4IgqGKqa26ntb0z0aGIyDBy3XXX8c1vfpN58+YddqkAYPbs2ZSVlVFWVsY111zDrbfeyj333MPs2bP5xS9+wc033wzAtddey6xZs5g5cyYLFy5kzpw53H///cycOZO5c+fyxhtv8IUvfOGw44nbC4OOtMN5YdAvX3iH7zz0Bi9+60zG5GUMcmQicijefPNNjj322ESHMaL09G+aqBcGDRvF2VEA9tSroVpEpIsSBEEVE0C12iFERPZTggCKc5QgRES6U4IAirKDW9Cq9DS1iMh+ShBAQWYaKaYShIhILCUIICXFKNKzECIiB9GT1CF1tyEisaqqqjjzzDMB2LlzJ5FIhJKSEgBWrFhBNBrtc//ly5cTjUZZuHDhe9bde++9rFq1ittuu23wAx9EShChIEGoBCEigffr7vv9LF++nJycnB4TxHChKqZQcXa6qphEpE+rV6/m1FNP5cQTT+SjH/0oO3bsAOCWW27huOOOY/bs2Vx00UVs2bKFO++8kx//+MfMnTuXZ599tl+ff9NNNzFz5kxmzpzJT37yEwAaGho477zzmDNnDjNnzuS+++4D4Bvf+Mb+Yw4kcQ2EShChouyo7mISGar+8A3Y+frgfubYWfCxG/u9ubvzla98hYcffpiSkhLuu+8+vv3tb7N06VJuvPFG3n77bdLT09m3bx8FBQVcccUVAyp1rF69mnvuuYcXX3wRd2fBggWceuqpbN68mfHjx/Poo48CQf9PVVVVPPjgg6xbtw4z29/l92BTCSJUlB2lpqmNtg71xyQi79XS0sIbb7zB2Wefzdy5c/nBD35ARUUFEPShdMkll/DLX/6y17fMvZ+//vWvXHDBBWRnZ5OTk8OFF17Is88+y6xZs3jiiSf4+te/zrPPPkt+fj75+flkZGTwpS99id/97ndkZWUN5qnupxJEqOthub2NrYzOVX9MIkPKAH7px4u7c/zxx/P888+/Z92jjz7KM888w+9//3tuuOEGXn998Eo706dP56WXXuKxxx7jO9/5DmeeeSbf/e53WbFiBX/5y1944IEHuO2223jyyScH7ZhdVIIIFYcPy6mhWkR6kp6eTmVl5f4E0dbWxpo1a+js7GTbtm2cfvrp/PCHP6Smpob6+npyc3Opq6vr9+efcsopPPTQQzQ2NtLQ0MCDDz7IKaecwrvvvktWVhaXXnop1157LS+99BL19fXU1NRw7rnn8uMf/5hXX301Lucc1xKEmZ0D3AxEgJ+6+43d1l8BXAl0APXA5e6+Nlz3TeBL4bol7v54PGPd3x+T2iFEpAcpKSk88MADLFmyhJqaGtrb2/nqV7/K9OnTufTSS6mpqcHdWbJkCQUFBXziE5/gU5/6FA8//DC33nrr/nc5dLn33nt56KGH9s+/8MILXHbZZcyfPx+Af/iHf2DevHk8/vjjXHvttaSkpJCWlsYdd9xBXV0dixYtorm5GXfnpptuiss5x627bzOLAG8BZwMVwErg4q4EEG6T5+614fT5wD+5+zlmdhzwP8B8YDzwZ2C6u/f6ktXD6e4b4K1ddXzkx89w68Xz+MSc8Yf8OSIyONTd9+AbSt19zwc2uvtmd28FlgGLYjfoSg6hbKArWy0Clrl7i7u/DWwMPy9u1KOriMjB4lnFVApsi5mvABZ038jMrgSuAaJA1wtUS4EXuu1b2sO+lwOXA0ycOPGwgi3MimKGnoUQEQklvJHa3W9396nA14HvDHDfu9293N3Lux6BP1SRFKMgM40qvTRIZMgYKW+8HAoO5d8yngliOzAhZr4sXNabZcAnD3HfQaHuNkSGjoyMDKqqqpQkBoG7U1VVRUbGwG7hj2cV00pgmplNJri4XwR8LnYDM5vm7hvC2fOArulHgF+b2U0EjdTTgBVxjBVQdxsiQ0lZWRkVFRVUVlYmOpQRISMjg7KysgHtE7cE4e7tZnYV8DjBba5L3X2NmV0PrHL3R4CrzOwsoA3YCywO911jZvcDa4F24Mq+7mAaLMU5UTbsro/3YUSkH9LS0pg8eXKiw0hqcX0Owt0fAx7rtuy7MdNX97HvDcAN8YvuvVTFJCJyQMIbqYeS4uwoextb6ehUnaeIiBJEjKLsKO6wr1GlCBERJYgYRTnqj0lEpIsSRIzi8GnqPeqPSURECSKWutsQETlACSJG8f4EoaepRUSUIGIUhglCD8uJiChBHCQtkkJ+ZpqqmEREUIJ4j+LsqEoQIiIoQbxHUXZUb5UTEUEJ4j3U3YaISEAJopviHFUxiYiAEsR7FIX9MXWqPyYRSXJKEN0UZafT0enUNLUlOhQRkYRSguhmVI6ehRARASWI91B3GyIiASWIborU3YaICKAE8R7F2UGX36piEpFkpwTRTWF2GoAelhORpKcE0U16aoTc9FSVIEQk6SlB9KBID8uJiChB9CTobkON1CKS3OKaIMzsHDNbb2YbzewbPay/xszWmtlrZvYXMzsqZl2Hmb0SDo/EM87uirPTqVIbhIgkubglCDOLALcDHwOOAy42s+O6bfYyUO7us4EHgB/FrGty97nhcH684uxJsTrsExGJawliPrDR3Te7eyuwDFgUu4G7P+XujeHsC0BZHOPpt6KcoD8md/XHJCLJK54JohTYFjNfES7rzZeAP8TMZ5jZKjN7wcw+GYf4elWcHaWtw6ltbj+ShxURGVJSEx0AgJldCpQDp8YsPsrdt5vZFOBJM3vd3Td12+9y4HKAiRMnDlo8sd1t5GemDdrniogMJ/EsQWwHJsTMl4XLDmJmZwHfBs539/23Drn79nC8GVgOzOu+r7vf7e7l7l5eUlIyaIGruw0RkfgmiJXANDObbGZR4CLgoLuRzGwecBdBctgds7zQzNLD6VHAycDaOMZ6kK7uNvboTiYRSWJxq2Jy93Yzuwp4HIgAS919jZldD6xy90eAfwdygN+YGcDW8I6lY4G7zKyTIInd6O5HLEEU5ahHVxGRuLZBuPtjwGPdln03ZvqsXvZ7DpgVz9j6Uqwuv0VE9CR1TzLSImRHI3pYTkSSmhJEL4py1N2GiCQ3JYheFGWnq8M+EUlqShC9UHcbIpLslCB6UaQEISJJTgmiF8XZwTsh1B+TiCQrJYheFGVHaW3vpL5F/TGJSHJSguhFcU7wNLWqmUQkWSlB9KLrYTndySQiyUoJohf7O+zTw3IikqSUIHpRpO42RCTJKUH0ojhHVUwiktyUIHqRFU0lIy1F3W2ISNJSguhDsbrbEJEkpgTRh6LsqHp0FZGkpQTRh+IcdbchIslLCaIP6o9JRJKZEkQfgv6Y1EgtIslJCaIPRdnpNLd10tiq/phEJPkoQfRhf3cbaqgWkSSkBNEHPU0tIslMCaIPRTlKECKSvOKaIMzsHDNbb2YbzewbPay/xszWmtlrZvYXMzsqZt1iM9sQDovjGWdv1KOriCSzuCUIM4sAtwMfA44DLjaz47pt9jJQ7u6zgQeAH4X7FgHfAxYA84HvmVlhvGLtTdc7IarqdSeTiCSfeJYg5gMb3X2zu7cCy4BFsRu4+1Pu3hjOvgCUhdMfBZ5w92p33ws8AZwTx1h7lB2NEE1NURWTiCSleCaIUmBbzHxFuKw3XwL+cIj7xoWZ7X83tYhIsklNdAAAZnYpUA6cOsD9LgcuB5g4cWIcItPT1CKSvOJZgtgOTIiZLwuXHcTMzgK+DZzv7i0D2dfd73b3cncvLykpGbTAYxWpBCEiSapfCcLMss0sJZyebmbnm1na++y2EphmZpPNLApcBDzS7XPnAXcRJIfdMaseBz5iZoVh4/RHwmVHXHF2VO+EEJGk1N8SxDNAhpmVAn8CPg/c29cO7t4OXEVwYX8TuN/d15jZ9WZ2frjZvwM5wG/M7BUzeyTctxr4N4IksxK4Plx2xBVlp+u91CKSlPrbBmHu3mhmXwL+091/ZGavvN9O7v4Y8Fi3Zd+NmT6rj32XAkv7GV/cFOdEaWjtoLmtg4y0SKLDERE5YvpbgjAz+yBwCfBouCwprpZ6WE5EklV/E8RXgW8CD4bVRFOAp+IW1RCyvz8mVTOJSJLpVxWTuz8NPA0QNlbvcfcl8QxsqCjO6SpBqKFaRJJLf+9i+rWZ5ZlZNvAGsNbMro1vaENDUXbQ3YaehRCRZNPfKqbj3L0W+CTB086TCe5kGvHU5beIJKv+Joi08LmHTwKPuHsb4HGLagjJy0glLWJqpBaRpNPfBHEXsAXIBp4Ju+WujVdQQ4mZUZgVVSO1iCSd/jZS3wLcErPoHTM7PT4hDT3FOekqQYhI0ulvI3W+md1kZqvC4f8RlCaSQtCjq+5iEpHk0t8qpqVAHfCZcKgF7olXUEONenQVkWTU3642prr738XM/2t/utoYKYqy1QYhIsmnvyWIJjP7UNeMmZ0MNMUnpKGnODtKXUs7Le0diQ5FROSI6W8J4grgv80sP5zfCyyOT0hDT1H4NPXehjbG5idFF1QiIv0rQbj7q+4+B5gNzHb3ecAZcY1sCDnQYZ8aqkUkeQzojXLuXhs+UQ1wTRziGZLU3YaIJKPDeeWoDVoUQ1xXh31KECKSTA4nQSRFVxsQU8WkO5lEJIn02UhtZnX0nAgMyIxLRENQXkYakRRTG4SIJJU+E4S75x6pQIaylJSwPyZVMYlIEjmcKqakUpwdVRWTiCQVJYh+UncbIpJslCD6qShHCUJEkosSRD8FPboqQYhI8ohrgjCzc8xsvZltNLNv9LD+w2b2kpm1m9mnuq3rMLNXwuGReMbZH8XZ6dQ0tdHW0ZnoUEREjoj+9sU0YGYWAW4HzgYqgJVm9oi7r43ZbCtwGfC1Hj6iyd3nxiu+gdrfH1NjK6NzMxIcjYhI/MWzBDEf2Ojum929FVgGLIrdwN23uPtrwJD/Wa6H5UQk2cQzQZQC22LmK8Jl/ZURvr3uBTP75KBGdgiKstXdhogkl7hVMQ2Co9x9u5lNAZ40s9fdfVPsBmZ2OXA5wMSJE+MazIEeXZUgRCQ5xLMEsR2YEDNfFi7rF3ffHo43A8uBeT1sc7e7l7t7eUlJyeFF+z72lyDq1d2GiCSHeCaIlcA0M5tsZlHgIqBfdyOZWaGZpYfTo4CTgbV97xVfBVlRzFTFJCLJI24Jwt3bgauAx4E3gfvdfY2ZXW9m5wOY2UlmVgF8GrjLzNaEux8LrDKzV4GngBu73f10xEXC/phUxSQiySKubRDu/hjwWLdl342ZXklQ9dR9v+eAWfGM7VAUq7sNEUkiepJ6AIr0NLWIJBEliAEozolSpUZqEUkSShADMC4/k4q9TVTWKUmIyMinBDEAlyyYSHunc/tTGxMdiohI3ClBDMCUkhw+Uz6BX734DtuqGxMdjohIXClBDNDVZ04jxYwfP/FWokMREYkrJYgBGpufwWULJ/HgK9tZt7M20eGIiMSNEsQh+PJpU8lJT+U/HlcpQkRGLiWIQ1CQFeWKU6fy5zd3sfqd6kSHIyISF0oQh+jvT57EqJx0fviH9bh7osMRERl0ShCHKCuaytVnHs2KLdUsf6sy0eGIiAw6JYjD8NmTJjKxKIsf/XE9nZ0qRYjIyKIEcRiiqSlcc/Z03txRy+9fezfR4YiIDColiMN0/pzxHDM2l5ueeIu2jiH/am0RkX5TgjhMKSnGdefM4J2qRu5bue39dxARGSaUIAbB6TNGc9KkQm7+ywaaWjsSHY6IyKBQghgEZsZ15xxDZV0L9zz3dqLDEREZFEoQg+SkSUWcecxo7ly+iZrGtkSHIyJy2JQgBtHXPjqDupZ27nh6U6JDERE5bEoQg+jYcXksmjOee/72NjtrmhMdjojIYVGCGGTXnD2Djk7nlic3JDoUEZHDogQxyCYWZ/G5BRO5b+U2Nu6uT3Q4IiKHLK4JwszOMbP1ZrbRzL7Rw/oPm9lLZtZuZp/qtm6xmW0Ih8XxjHOwXXXG0WRHI3zx3pWqahKRYStuCcLMIsDtwMeA44CLzey4bpttBS4Dft1t3yLge8ACYD7wPTMrjFesg210bgY//+J8qupbuOSnL7CnviXRIYmIDFg8SxDzgY3uvtndW4FlwKLYDdx9i7u/BnTvo+KjwBPuXu3ue4EngHPiGOugmzexkKWXncT2fU1c+tMX2dfYmuiQREQGJJ4JohSI7XuiIlwW732HjAVTivmvL5SzubKBLyxdQW2zno8QkeFjWDdSm9nlZrbKzFZVVg7NdzKcMq2E/7zkBNa+W8sX71lJY2t7okMSEemXeCaI7cCEmPmycNmg7evud7t7ubuXl5SUHHKg8XbWcWO4+aJ5vLR1L//w81U0t6m/JhEZ+uKZIFYC08xssplFgYuAR/q57+PAR8ysMGyc/ki4bNg6b/Y4/uPTc3h+cxVf/uVqWtvVNbiIDG1xSxDu3g5cRXBhfxO4393XmNn1ZnY+gJmdZGYVwKeBu8xsTbhvNfBvBElmJXB9uGxYu/CEMn7wyZk8tb6SJf/zMu16f4SIDGHmPjJelVleXu6rVq1KdBj98rO/vs2//e9aFs0dz02fmUskxRIdkogkKTNb7e7lPa1LPdLBCHzpQ5Npbuvg3x9fT2ZahP97wSxSlCREZIhRgkiQK08/mqbWDm57aiNpkRS+f/7xKkmIyJCiBJFA/99HptPa0cndz2xm295Gbr5oHvmZaYkOS0QEGObPQQx3Zsa3zj2WH3xyJn/dsIcLbv+bOvgTkSFDCWIIuPQDR/Hr//MBaprauOD2v/HUut2JDklERAliqJg/uYiHrzqZCUVZfPHnK7lj+SZGyh1mIjI8KUEMIWWFWfz2yws5b9Y4fvjHdVy97BWaWvXUtYgkhhqph5jMaIRbL57HsePy+I8/rWfznnru+nw5pQWZiQ5NRJKMShBDkJlx5elH89MvlLNlTyOLbvsrK7cM+wfJRWSYUYIYws48dgwPXbmQ3Iw0PvdfL/A/K7YmOiQRSSLqamMYqGls4yvLXuaZtyqZMiqbU2eUcNqM0SyYXERGWiTR4YnIMNZXVxtKEMNER6ezbOVW/rRmFy9srqKlvZOMtBQWTh3FaTNKOG36aCYWZyU6TBEZZpQgRpim1g5eeLuK5et2s/ytSt6pagRQ6UJEBkwJYoR7e08Dy9fvZvn6yv2li8KsNK48/Wgu/cBRShQi0isliCTS1NrBC5urWPq3t3l2wx5KCzL56lnTuPCEMnUGKCLvoQSRpP62cQ8//OM6XquoYdroHK796AzOPm4MZkoUIhLoK0HoNtcR7OSjR/HwlSfzn5ecQEenc/kvVnPhHc/xwuaqRIcmIsOAEsQIZ2acO2scf/rnD3PjhbPYsa+Zi+5+gcVLV7Dm3ZpEhyciQ5iqmACa9kFmwWCGM2Q1t3Xw8+e28J/LN1HT1Mb5c8bz2ZMmUD6pkPRUNWaLJBu1QfSl+m342dlwytfgA1cMfmBDVE1TG3c/s4mlf91CU1sHWdHIgWcqZpRQVqhnKkSSgd5J3Ze8Upj4Afjj16G9CT70z4mO6IjIz0zj2o8ewz+ddjTPbaraf5vsn9/cBcDUkmxOmzGa02aUMH9ykUoXIklIJQiAjnZ46Ap4/Tdw6tfhtG9CEt7p4+5sqgyeqXj6rUpe3FxNa0cnmWkRFk4t5qzjxvDx2ePIzdBrUUVGClUx9UdnB/x+Cbz8S1j4FTj735IyScRqbG3n+U1VPP1WJcvXV7K1upGsaISPzx7HxfMnMndCgW6ZFRnmElbFZGbnADcDEeCn7n5jt/XpwH8DJwJVwGfdfYuZTQLeBNaHm77g7vFtIEiJwCduhbQseO5WaGuCj/07pCTvjV5Z0VTOPHYMZx47BnfnlW37WLZiG4+8+i73r6rgmLG5XHTSBC6YV0Z+lkoVIiNN3EoQZhYB3gLOBiqAlcDF7r42Zpt/Ama7+xVmdhFwgbt/NkwQ/+vuM/t7vEF7UM4dnvguPHcLzLsUPnFLkDxkv7rmNh559V2WrdjG69trSE9N4dxZ47jopAnMn1ykUoXIMJKoEsR8YKO7bw6DWAYsAtbGbLMI+H44/QBwmyX66mIGZ18flCSevhHamuGCOyGiX8hdcjPSuGTBUVyy4Cje2F7DspVbefjld3nw5e1MKcnmopMm8IEpxUwbnUtmVMlVZLiKZ4IoBbbFzFcAC3rbxt3bzawGKA7XTTazl4Fa4Dvu/mz3A5jZ5cDlABMnThy8yM3g9G9CWgb8+fvQ3gyfugdSo4N3jBFiZmk+PyidxbfOPZZHX9vBspXb+L+PrQMgxWBScTYzxuYyY2wux4zN45ixuUwsyiJlAP1CuTutHZ26k0rkCBuqt7nuACa6e5WZnQg8ZGbHu3tt7EbufjdwNwRVTIMexYf+OShJ/OE6WPY5+OwvIE3vhu5JVjSVT5dP4NPlE9hW3cgb22tYt7OOdTtreXNHLX9cs5Ou2szMtAjTx+RwzNg8RuelU9/STkNLO/Ut7dQ1H5iubw7HLe10OhxVnMWJRxVSflQRJ00qZGpJzoASjYgMTDwTxHZgQsx8Wbisp20qzCwVyAeqPGgYaQFw99VmtgmYDhz53vgW/COkpsPvvwq/+jRcvAzSc454GMPJhKIsJhRl8bFZ4/Yva2xtZ8OuetbtrGXdzjrW76zjiTd3sbexlZxoKjkZqeSkp5KdnkpuRiqjczP2L8tJTyUtksLaHTU8vb6S370U/BnlZ6YFCWNSkDRml+Wra3ORQRTPBLESmGZmkwkSwUXA57pt8wiwGHge+BTwpLu7mZUA1e7eYWZTgGnA5jjG2rcTL4PUzOBZiaUfhYVL4LhFQRWU9EtWNJU5EwqYM6Fg/7KuGyQG0uzk7mypamTllmpWb9nLyneqeXLdbgCikRRmluYxqzSf0sJMxhdkMi4/k9KCTEpy09XducgAxfU5CDM7F/gJwW2uS939BjO7Hljl7o+YWQbwC2AeUA1c5O6bzezvgOuBNqAT+J67/76vYx2R7r7XPQZ/+g5Ub4KsYph7CZT/PRRNie9xpU/VDa2sfmcvq7ZUs3JLNW/tqqe+pf2gbVJTjLH5GYwvyGR817ggk6NH5zBjTC6F2WpfkmGkvRVqK2DvO7DvneAH7JzPHtJH6UG5wdTZCW8/Dat+FiQM74CpZ0L5F2H6ORAZqs06yaW2uY139zWFQ/OB6ZpgemdNM+2dB/72S3LTmTEml+ljcpkxNofpY3KZNiaXnHR9n/I+2prhnb8F3fYUHz041wB3qNsBe7ccSAKx47p3wTsPbD9uDvzjM4d0KCWIeKl9F176Bay+N/jC8krhhMVwwhcgb9z77i6J09Hp7KptZuPuetbvrGP9rjreCofmtgP/8coKM5kRJoujR+cwtSSbqaNzyFN3I1L7Lqz8afD/vzF8x0pqBow+DsbOCofZMOb43tst3aF2O+xeB5XroPLNcHo9tNbFbGiQOw4Kj4KCo947zht/yM9rKUHEW0c7vPXHoFSx6UmwCBxzLkw9I/gDGX0cRNU76nDQ2els29vI+p1Bsli/q571O2t5e08DbR0H/q+Mzk0PE0bOQeMxeekj60HBtubgtu/U9MP/rI624Ndv1QZoqAzmOzugsy2cbg+G7tPtzdDeEo7Doa05ZnlTMPZOiKQHt6OnZkAkGsTdfRzNhtJymHo6FBzC7fHbVsKLd8Dah4P4Z5wLJ3wemmth52vh8Do07Q13MCieeiBpRNKDRFC5PhhaYm7OzC6BkmPCYQYUTYaCSVAwYXC+gx4oQRxJ1Zth1T3wyq+hcU+wzFKComfXL4qucU5JYmOVfmvr6GRbdSMbd9ezqbKBjbvr2VhZz+bd9dS1tAPODNvGaWlrsbRMaiNF1KYV05A2iqZoEZFoOumpEdJTU8IhQmY0QnZ6hOzwTq3saOqB6fTI/ru6sqIROjqdlvZOWts7ae0Ixl3zLe0d+5fnpKdy/Ph8SnL7uJi01MOuN6B+V/DLt7EKGqtjpmOWtdYH++SMCS6mBRMhf0I4fVRw4cqfcPAPoIaqIAns2RCON8Ket2Dv28FF//1YCqSkQkpaUF2TmhFcHFMzg3FaOE7NODCkZQAGHa1BsuhoPZBADlrWAs37DvziL5oaJIopp8PkUyAjv+eY2lth7UPw4p2wfTWk58G8z8P8/xNcxLvrKhnsfD0cwqSxd0uwPjYRjD4GSo4NprOL3/tZcaYEkQjusG9rzB9IONRsPbBNztggWYyaDtmjgobv7kNmgbr6GEztrcFFa9ea4AJWNAUmzA/GA/3l39mBb3uRxtceJrL+MTLqt/a6aY3lsTelkCorpJJCdncWsLMzl53tOezpzKXK86j2PKrJpYXDbzAfm5fBzNJ8Zo3PZUHeHo7rWE9e1atQsQp2rz24/hogmgtZRT38DRYF2+7bemCoqQh+9cfKLgn+nmsrYn45E/xqL5oS/EAaNQ2KpwXj3LHBupTUYIikHUgK8e7/zD345b75Kdj0FGz5K7Q1BImp9MQgWUw9HcpOCl4mtvoeWPkzqN8ZnMeCK2DOxYd2u3tzTVDjkIBE0BsliKGksTr49RabNKo3Q1tjz9tbCmQWHvgPmzsuqG/MK4X80mCcVwo5o/uXSNpbgv/ATfuCcXMNpOeG/8FLIKMgfr3YdrQHx2veFxy/eR/gwbGzRwdJcrC6NHGH+t2w6/UgGXQNlevfe3GD4N+2bD5MOAkmLIDxJ/RcLdjWDJuXw7r/hfV/CEqJkShMPhWO/ThM+0iwXd3O4Bd617h+F9TtCi4ydeF8T3EAHanZtKYX0hwtojG1gIbUAtqieXSGg2fk4en5WEYelplPSmYBqZkFRLLyqN1bSdX656BiJcX7Xmd6+1vkWRMAtWTzTsaxNJTMJf2okygpncLosaVEc0cNrPqiszM4j31bYd+2oOF039bgXPPGHUgCxUcHpYyhfuNGeytUrDyQMN59KUiK0Zyg1NHRCkefFSSGqWeOuA48lSCGg9ZGaKo+uHjfsOfgIn/DnuDOhtrtQfE5Vkrqwckjmn3gQty098DQWyLa/zlpwYU6uyRmGBUkoGh2cJHvaD1Qb9zRFv4naguXhdPNtcHxm2sOJIOu6oq+ZBaGySJMWF3TXb+42luho6u6oGu6LaxCCKfrdgbJoKuKDyB3fNBYOOb4oNQ25vjgl23VRti2IrhAbHsxmIegHWnsrKB0UTYf8CApbPhz8GszmgvTPwLHfDy4eGTk9edbPqCz80BVR8OeINbY77v7suaa/v37dbEIjDmetnEnsi3reF7qPJrn9ubz2rt1bKqs3/9Ue4pBaWEmk4qzOao4i6OKgvGkUdlMLMo66MHD1vZOqhta2VPfQmV9C3vqWqhqaGVPXQt76lvY19TGqJx0JhRmMaEok4nhA5MlOenD64n3pr3w9rPBD4FINLhDsWR6oqOKGyWIkcY9+COuqQjupKgNxzXbg+RRuz1IOJmF3YaCcIhZlp4fNJI17AkaDht2h+Ou+UqorwwaAntikeBXf1d1QSQaDOm5wbEy8oNSSW/TZuExdsccb3fMeA+01PT+bxGJHmiY7Dp2VlGYDGaGw/HBsv5orD6QLLatgO0vBQkBgnr4GecGJYVJp8St0bBXHe3Bd9VSG5bEwnHsfFomlJXDuLm93hjR0NLOup11bNnTwDtVDWypauSdqgbeqW5kX+PBpZpx+RlkRSPsqW+lpqnnEk9mWoRRuVHyM9OorGthV23LQeujqSmUFWbuTxwTCrMYm59BQVaUgsw0CrLSKMiMkpuR2mciaWnv4N19zVTsbWRbdVMw3tu0f97dmVCUFSa6LCYWB0nuqOIsRueOsJsHBpEShBwed2htCIZIWkxCOAL1xRBU6zRWBdVtqenh8cNxvP/Td7TD7jVB4+q4eSOueqG7fY2tvFPVyJaqhv3j5rYORuWk7x+Kc6KMykmnJCedUblRsqIHVyE1t3WwfV8T26rDC3h1I9v2NrK1OriQ95ZoUgzyMtPCpBGlICuN7Ggqu+ua2VbdxK66ZmIvV6kpxviCTCYUZVJWkEVKCmytbuSdqkbe3ddEzGMuZKSlMLEoi4lhCWlcfgbj8jMZm5/BuPwMSnLTSYv077ttau3g3ZomdnQ9X1PTxO66FjLTIuRnppGXkUp+Vhp5GWnkZwZDXjhOT02JS6Lq7PRDLqUpQYjIkFHb3Mbu2hZqmlrZ19gWDE1t1DS2sq/p4Pm6lnZKctIpC0sfZYVZTCjMpKwoi7F5Gb12n9La3sn2fU28U9WwP2lsrW5kazhuaus4aHszKMlJZ1x+BmPzMxibl8HY/ExSjIMesNxR00x1Q+t79i3MitLS1kFD68Gf2100kkJRdpQx+RmMyU1nbH4GY/K6jhdMj8lLP+i1vvUt7eysaQ6G2mZ21jSF4+b946klOdz3jx88pO8jYW+UExHpLi8jLe4PGkZTU5g8KpvJo7Lfs87dqW1qZ0dtcMHfWdPMjppmdtU0s6O2mbf3NPDcpirqmoNbcnMzUhmfn8n4ggzmTigIu2nJ2N/P15i8DKKpQemjraOT2qY2apvbqWlqo7apjZpwqG0OxlX1rewKj/PC5ipqm9976292NEJRTpR9DW3hbdQHK8xKY0xeUPqZVZrPMWMH2AbWT0oQIpJUzIz8rDTys9L6vLDWt7Tj7gf9mn8/aZEUinPSKc7pf/tUY2s7u2pb2FnTzK7aYNhZG5RUCrOi3Uo1QSnjSPVarAQhItKDI9UPV1Y0lcmjUnss7STayG5xExGRQ6YEISIiPVKCEBGRHilBiIhIj5QgRESkR0oQIiLSIyUIERHpkRKEiIj0aMT0xWRmlcA73RaPAvb0sPlwNtLOaaSdD4y8cxpp5wMj75wO53yOcvceX285YhJET8xsVW+dUA1XI+2cRtr5wMg7p5F2PjDyzile56MqJhER6ZEShIiI9GikJ4i7Ex1AHIy0cxpp5wMj75xG2vnAyDunuJzPiG6DEBGRQzfSSxAiInKIRmyCMLNzzGy9mW00s28kOp7DZWZbzOx1M3vFzIblu1XNbKmZ7TazN2KWFZnZE2a2IRwXJjLGgejlfL5vZtvD7+kVMzs3kTEOlJlNMLOnzGytma0xs6vD5cPye+rjfIbt92RmGWa2wsxeDc/pX8Plk83sxfCad5+ZRQ/7WCOxisnMIsBbwNlABbASuNjd1yY0sMNgZluAcncftvdum9mHgXrgv919ZrjsR0C1u98YJvJCd/96IuPsr17O5/tAvbv/RyJjO1RmNg4Y5+4vmVkusBr4JHAZw/B76uN8PsMw/Z7MzIBsd683szTgr8DVwDXA79x9mZndCbzq7ncczrFGagliPrDR3Te7eyuwDFiU4JiSnrs/A1R3W7wI+Hk4/XOC/7zDQi/nM6y5+w53fymcrgPeBEoZpt9TH+czbHmgPpxNCwcHzgAeCJcPync0UhNEKbAtZr6CYf5HQfAH8CczW21mlyc6mEE0xt13hNM7gTGJDGaQXGVmr4VVUMOiKqYnZjYJmAe8yAj4nrqdDwzj78nMImb2CrAbeALYBOxz9/Zwk0G55o3UBDESfcjdTwA+BlwZVm+MKB7Udw73Os87gKnAXGAH8P8SGs0hMrMc4LfAV929NnbdcPyeejifYf09uXuHu88FyghqTI6Jx3FGaoLYDkyImS8Llw1b7r49HO8GHiT4oxgJdoX1xF31xbsTHM9hcfdd4X/eTuC/GIbfU1iv/VvgV+7+u3DxsP2eejqfkfA9Abj7PuAp4INAgZmlhqsG5Zo3UhPESmBa2KofBS4CHklwTIfMzLLDBjbMLBv4CPBG33sNG48Ai8PpxcDDCYzlsHVdREMXMMy+p7AB9GfAm+5+U8yqYfk99XY+w/l7MrMSMysIpzMJbsZ5kyBRfCrcbFC+oxF5FxNAeNvaT4AIsNTdb0hsRIfOzKYQlBoAUoFfD8fzMbP/AU4j6HlyF/A94CHgfmAiQW+8n3H3YdHw28v5nEZQbeHAFuAfY+ruhzwz+xDwLPA60Bku/hZBvf2w+576OJ+LGabfk5nNJmiEjhD8yL/f3a8PrxPLgCLgZeBSd285rGON1AQhIiKHZ6RWMYmIyGFSghARkR4pQYiISI+UIEREpEdKECIi0iMlCJEBMLOOmB5AXxnMnoLNbFJsz7AiiZb6/puISIymsIsDkRFPJQiRQRC+r+NH4Ts7VpjZ0eHySWb2ZNgp3F/MbGK4fIyZPRj26f+qmS0MPypiZv8V9vP/p/BJWZGEUIIQGZjMblVMn41ZV+Pus4DbCJ7iB7gV+Lm7zwZ+BdwSLr8FeNrd5wAnAGvC5dOA2939eGAf8HdxPRuRPuhJapEBMLN6d8/pYfkW4Ax33xx2DrfT3YvNbA/BC2vawuU73H2UmVUCZbFdIYTdUT/h7tPC+a8Dae7+gyNwaiLvoRKEyODxXqYHIrbvnA7UTigJpAQhMng+GzN+Ppx+jqA3YYBLCDqOA/gL8GXY//KX/CMVpEh/6deJyMBkhm/y6vJHd++61bXQzF4jKAVcHC77CnCPmV0LVAJ/Hy6/GrjbzL5EUFL4MsGLa0SGDLVBiAyCsA2i3N33JDoWkcGiKiYREemRShAiItIjlSBERKRHShAiItIjJQgREemREoSIiPRICUJERHqkBCEiIj36/wFVsOYiI3ST8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 978    0    0    0    0    0    1    1    0    0]\n",
      " [   0 1133    1    0    0    0    0    1    0    0]\n",
      " [   1    3 1021    1    1    0    0    5    0    0]\n",
      " [   0    0    1 1005    0    3    0    0    1    0]\n",
      " [   0    0    0    0  974    0    1    0    1    6]\n",
      " [   2    0    0    5    0  883    1    0    0    1]\n",
      " [   2    3    0    1    1    3  948    0    0    0]\n",
      " [   0    3    4    1    0    0    0 1020    0    0]\n",
      " [   4    1    1    1    1    0    1    3  959    3]\n",
      " [   1    2    0    1    6    3    0    6    3  987]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from models.models import CNN, CNN_d\n",
    "\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "#  Create an instance of the CNN\n",
    "model = CNN_d().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize lists to store the train and test losses for each epoch\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    print(f'Train Accuracy: {(100 * correct / total):.2f}%')\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    # Print test accuracy at the end of each epoch\n",
    "    test_accuracy = (100 * correct / total)\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Plot the train and test losses for each epoch\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5c986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
