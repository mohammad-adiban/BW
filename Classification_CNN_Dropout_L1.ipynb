{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2215a934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [100/938], Loss: 0.6287\n",
      "Epoch [1/30], Step [200/938], Loss: 0.6338\n",
      "Epoch [1/30], Step [300/938], Loss: 0.6843\n",
      "Epoch [1/30], Step [400/938], Loss: 0.4409\n",
      "Epoch [1/30], Step [500/938], Loss: 0.5181\n",
      "Epoch [1/30], Step [600/938], Loss: 0.6467\n",
      "Epoch [1/30], Step [700/938], Loss: 0.3979\n",
      "Epoch [1/30], Step [800/938], Loss: 0.6507\n",
      "Epoch [1/30], Step [900/938], Loss: 0.3709\n",
      "Train Accuracy: 92.44%\n",
      "Test Accuracy: 98.18%\n",
      "Test Loss: 0.0600\n",
      "Epoch [2/30], Step [100/938], Loss: 0.4199\n",
      "Epoch [2/30], Step [200/938], Loss: 0.3218\n",
      "Epoch [2/30], Step [300/938], Loss: 0.3061\n",
      "Epoch [2/30], Step [400/938], Loss: 0.3152\n",
      "Epoch [2/30], Step [500/938], Loss: 0.3350\n",
      "Epoch [2/30], Step [600/938], Loss: 0.4002\n",
      "Epoch [2/30], Step [700/938], Loss: 0.3287\n",
      "Epoch [2/30], Step [800/938], Loss: 0.4002\n",
      "Epoch [2/30], Step [900/938], Loss: 0.2809\n",
      "Train Accuracy: 96.39%\n",
      "Test Accuracy: 98.50%\n",
      "Test Loss: 0.0515\n",
      "Epoch [3/30], Step [100/938], Loss: 0.2975\n",
      "Epoch [3/30], Step [200/938], Loss: 0.3098\n",
      "Epoch [3/30], Step [300/938], Loss: 0.3028\n",
      "Epoch [3/30], Step [400/938], Loss: 0.3370\n",
      "Epoch [3/30], Step [500/938], Loss: 0.3730\n",
      "Epoch [3/30], Step [600/938], Loss: 0.2567\n",
      "Epoch [3/30], Step [700/938], Loss: 0.2431\n",
      "Epoch [3/30], Step [800/938], Loss: 0.2596\n",
      "Epoch [3/30], Step [900/938], Loss: 0.3681\n",
      "Train Accuracy: 96.88%\n",
      "Test Accuracy: 98.47%\n",
      "Test Loss: 0.0488\n",
      "Epoch [4/30], Step [100/938], Loss: 0.2981\n",
      "Epoch [4/30], Step [200/938], Loss: 0.2691\n",
      "Epoch [4/30], Step [300/938], Loss: 0.2976\n",
      "Epoch [4/30], Step [400/938], Loss: 0.2059\n",
      "Epoch [4/30], Step [500/938], Loss: 0.3512\n",
      "Epoch [4/30], Step [600/938], Loss: 0.3858\n",
      "Epoch [4/30], Step [700/938], Loss: 0.3435\n",
      "Epoch [4/30], Step [800/938], Loss: 0.2333\n",
      "Epoch [4/30], Step [900/938], Loss: 0.3225\n",
      "Train Accuracy: 97.28%\n",
      "Test Accuracy: 98.39%\n",
      "Test Loss: 0.0502\n",
      "Epoch [5/30], Step [100/938], Loss: 0.2461\n",
      "Epoch [5/30], Step [200/938], Loss: 0.2201\n",
      "Epoch [5/30], Step [300/938], Loss: 0.2315\n",
      "Epoch [5/30], Step [400/938], Loss: 0.3669\n",
      "Epoch [5/30], Step [500/938], Loss: 0.2036\n",
      "Epoch [5/30], Step [600/938], Loss: 0.2715\n",
      "Epoch [5/30], Step [700/938], Loss: 0.3956\n",
      "Epoch [5/30], Step [800/938], Loss: 0.3541\n",
      "Epoch [5/30], Step [900/938], Loss: 0.1905\n",
      "Train Accuracy: 97.27%\n",
      "Test Accuracy: 98.64%\n",
      "Test Loss: 0.0423\n",
      "Epoch [6/30], Step [100/938], Loss: 0.2601\n",
      "Epoch [6/30], Step [200/938], Loss: 0.2719\n",
      "Epoch [6/30], Step [300/938], Loss: 0.4150\n",
      "Epoch [6/30], Step [400/938], Loss: 0.2474\n",
      "Epoch [6/30], Step [500/938], Loss: 0.4199\n",
      "Epoch [6/30], Step [600/938], Loss: 0.3056\n",
      "Epoch [6/30], Step [700/938], Loss: 0.2067\n",
      "Epoch [6/30], Step [800/938], Loss: 0.2953\n",
      "Epoch [6/30], Step [900/938], Loss: 0.2402\n",
      "Train Accuracy: 97.38%\n",
      "Test Accuracy: 98.69%\n",
      "Test Loss: 0.0409\n",
      "Epoch [7/30], Step [100/938], Loss: 0.2464\n",
      "Epoch [7/30], Step [200/938], Loss: 0.2861\n",
      "Epoch [7/30], Step [300/938], Loss: 0.2288\n",
      "Epoch [7/30], Step [400/938], Loss: 0.1914\n",
      "Epoch [7/30], Step [500/938], Loss: 0.2308\n",
      "Epoch [7/30], Step [600/938], Loss: 0.2773\n",
      "Epoch [7/30], Step [700/938], Loss: 0.2989\n",
      "Epoch [7/30], Step [800/938], Loss: 0.1902\n",
      "Epoch [7/30], Step [900/938], Loss: 0.3285\n",
      "Train Accuracy: 97.48%\n",
      "Test Accuracy: 98.43%\n",
      "Test Loss: 0.0457\n",
      "Epoch [8/30], Step [100/938], Loss: 0.2671\n",
      "Epoch [8/30], Step [200/938], Loss: 0.3835\n",
      "Epoch [8/30], Step [300/938], Loss: 0.2304\n",
      "Epoch [8/30], Step [400/938], Loss: 0.2789\n",
      "Epoch [8/30], Step [500/938], Loss: 0.2622\n",
      "Epoch [8/30], Step [600/938], Loss: 0.3349\n",
      "Epoch [8/30], Step [700/938], Loss: 0.2961\n",
      "Epoch [8/30], Step [800/938], Loss: 0.3435\n",
      "Epoch [8/30], Step [900/938], Loss: 0.2644\n",
      "Train Accuracy: 97.54%\n",
      "Test Accuracy: 98.54%\n",
      "Test Loss: 0.0444\n",
      "Epoch [9/30], Step [100/938], Loss: 0.2212\n",
      "Epoch [9/30], Step [200/938], Loss: 0.2548\n",
      "Epoch [9/30], Step [300/938], Loss: 0.2270\n",
      "Epoch [9/30], Step [400/938], Loss: 0.2530\n",
      "Epoch [9/30], Step [500/938], Loss: 0.2176\n",
      "Epoch [9/30], Step [600/938], Loss: 0.2782\n",
      "Epoch [9/30], Step [700/938], Loss: 0.2777\n",
      "Epoch [9/30], Step [800/938], Loss: 0.2248\n",
      "Epoch [9/30], Step [900/938], Loss: 0.2111\n",
      "Train Accuracy: 97.50%\n",
      "Test Accuracy: 98.71%\n",
      "Test Loss: 0.0386\n",
      "Epoch [10/30], Step [100/938], Loss: 0.2947\n",
      "Epoch [10/30], Step [200/938], Loss: 0.4904\n",
      "Epoch [10/30], Step [300/938], Loss: 0.2292\n",
      "Epoch [10/30], Step [400/938], Loss: 0.2899\n",
      "Epoch [10/30], Step [500/938], Loss: 0.3059\n",
      "Epoch [10/30], Step [600/938], Loss: 0.2130\n",
      "Epoch [10/30], Step [700/938], Loss: 0.2816\n",
      "Epoch [10/30], Step [800/938], Loss: 0.2334\n",
      "Epoch [10/30], Step [900/938], Loss: 0.2783\n",
      "Train Accuracy: 97.52%\n",
      "Test Accuracy: 98.54%\n",
      "Test Loss: 0.0443\n",
      "Epoch [11/30], Step [100/938], Loss: 0.2571\n",
      "Epoch [11/30], Step [200/938], Loss: 0.2118\n",
      "Epoch [11/30], Step [300/938], Loss: 0.2682\n",
      "Epoch [11/30], Step [400/938], Loss: 0.2994\n",
      "Epoch [11/30], Step [500/938], Loss: 0.3635\n",
      "Epoch [11/30], Step [600/938], Loss: 0.2602\n",
      "Epoch [11/30], Step [700/938], Loss: 0.4326\n",
      "Epoch [11/30], Step [800/938], Loss: 0.3645\n",
      "Epoch [11/30], Step [900/938], Loss: 0.2711\n",
      "Train Accuracy: 97.65%\n",
      "Test Accuracy: 98.75%\n",
      "Test Loss: 0.0369\n",
      "Epoch [12/30], Step [100/938], Loss: 0.3575\n",
      "Epoch [12/30], Step [200/938], Loss: 0.1938\n",
      "Epoch [12/30], Step [300/938], Loss: 0.3686\n",
      "Epoch [12/30], Step [400/938], Loss: 0.2397\n",
      "Epoch [12/30], Step [500/938], Loss: 0.2044\n",
      "Epoch [12/30], Step [600/938], Loss: 0.2720\n",
      "Epoch [12/30], Step [700/938], Loss: 0.2347\n",
      "Epoch [12/30], Step [800/938], Loss: 0.3313\n",
      "Epoch [12/30], Step [900/938], Loss: 0.2387\n",
      "Train Accuracy: 97.56%\n",
      "Test Accuracy: 98.62%\n",
      "Test Loss: 0.0416\n",
      "Epoch [13/30], Step [100/938], Loss: 0.1987\n",
      "Epoch [13/30], Step [200/938], Loss: 0.2711\n",
      "Epoch [13/30], Step [300/938], Loss: 0.3005\n",
      "Epoch [13/30], Step [400/938], Loss: 0.1880\n",
      "Epoch [13/30], Step [500/938], Loss: 0.4545\n",
      "Epoch [13/30], Step [600/938], Loss: 0.3182\n",
      "Epoch [13/30], Step [700/938], Loss: 0.2477\n",
      "Epoch [13/30], Step [800/938], Loss: 0.2249\n",
      "Epoch [13/30], Step [900/938], Loss: 0.2655\n",
      "Train Accuracy: 97.64%\n",
      "Test Accuracy: 98.45%\n",
      "Test Loss: 0.0460\n",
      "Epoch [14/30], Step [100/938], Loss: 0.2155\n",
      "Epoch [14/30], Step [200/938], Loss: 0.2843\n",
      "Epoch [14/30], Step [300/938], Loss: 0.2116\n",
      "Epoch [14/30], Step [400/938], Loss: 0.2243\n",
      "Epoch [14/30], Step [500/938], Loss: 0.3113\n",
      "Epoch [14/30], Step [600/938], Loss: 0.2722\n",
      "Epoch [14/30], Step [700/938], Loss: 0.1953\n",
      "Epoch [14/30], Step [800/938], Loss: 0.2025\n",
      "Epoch [14/30], Step [900/938], Loss: 0.2723\n",
      "Train Accuracy: 97.65%\n",
      "Test Accuracy: 98.79%\n",
      "Test Loss: 0.0365\n",
      "Epoch [15/30], Step [100/938], Loss: 0.2549\n",
      "Epoch [15/30], Step [200/938], Loss: 0.2080\n",
      "Epoch [15/30], Step [300/938], Loss: 0.2367\n",
      "Epoch [15/30], Step [400/938], Loss: 0.4196\n",
      "Epoch [15/30], Step [500/938], Loss: 0.2341\n",
      "Epoch [15/30], Step [600/938], Loss: 0.2796\n",
      "Epoch [15/30], Step [700/938], Loss: 0.2428\n",
      "Epoch [15/30], Step [800/938], Loss: 0.2437\n",
      "Epoch [15/30], Step [900/938], Loss: 0.1912\n",
      "Train Accuracy: 97.71%\n",
      "Test Accuracy: 98.68%\n",
      "Test Loss: 0.0390\n",
      "Epoch [16/30], Step [100/938], Loss: 0.2696\n",
      "Epoch [16/30], Step [200/938], Loss: 0.2561\n",
      "Epoch [16/30], Step [300/938], Loss: 0.1889\n",
      "Epoch [16/30], Step [400/938], Loss: 0.2805\n",
      "Epoch [16/30], Step [500/938], Loss: 0.2615\n",
      "Epoch [16/30], Step [600/938], Loss: 0.1974\n",
      "Epoch [16/30], Step [700/938], Loss: 0.2253\n",
      "Epoch [16/30], Step [800/938], Loss: 0.3043\n",
      "Epoch [16/30], Step [900/938], Loss: 0.2123\n",
      "Train Accuracy: 97.61%\n",
      "Test Accuracy: 98.73%\n",
      "Test Loss: 0.0384\n",
      "Epoch [17/30], Step [100/938], Loss: 0.2938\n",
      "Epoch [17/30], Step [200/938], Loss: 0.2578\n",
      "Epoch [17/30], Step [300/938], Loss: 0.3350\n",
      "Epoch [17/30], Step [400/938], Loss: 0.2168\n",
      "Epoch [17/30], Step [500/938], Loss: 0.2670\n",
      "Epoch [17/30], Step [600/938], Loss: 0.2314\n",
      "Epoch [17/30], Step [700/938], Loss: 0.2197\n",
      "Epoch [17/30], Step [800/938], Loss: 0.2662\n",
      "Epoch [17/30], Step [900/938], Loss: 0.2596\n",
      "Train Accuracy: 97.67%\n",
      "Test Accuracy: 98.73%\n",
      "Test Loss: 0.0402\n",
      "Epoch [18/30], Step [100/938], Loss: 0.1945\n",
      "Epoch [18/30], Step [200/938], Loss: 0.2882\n",
      "Epoch [18/30], Step [300/938], Loss: 0.2624\n",
      "Epoch [18/30], Step [400/938], Loss: 0.3014\n",
      "Epoch [18/30], Step [500/938], Loss: 0.3978\n",
      "Epoch [18/30], Step [600/938], Loss: 0.2266\n",
      "Epoch [18/30], Step [700/938], Loss: 0.2877\n",
      "Epoch [18/30], Step [800/938], Loss: 0.2136\n",
      "Epoch [18/30], Step [900/938], Loss: 0.2044\n",
      "Train Accuracy: 97.77%\n",
      "Test Accuracy: 98.73%\n",
      "Test Loss: 0.0401\n",
      "Epoch [19/30], Step [100/938], Loss: 0.2087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/30], Step [200/938], Loss: 0.2482\n",
      "Epoch [19/30], Step [300/938], Loss: 0.2175\n",
      "Epoch [19/30], Step [400/938], Loss: 0.3176\n",
      "Epoch [19/30], Step [500/938], Loss: 0.2284\n",
      "Epoch [19/30], Step [600/938], Loss: 0.3335\n",
      "Epoch [19/30], Step [700/938], Loss: 0.2125\n",
      "Epoch [19/30], Step [800/938], Loss: 0.2544\n",
      "Epoch [19/30], Step [900/938], Loss: 0.2470\n",
      "Train Accuracy: 97.78%\n",
      "Test Accuracy: 98.57%\n",
      "Test Loss: 0.0408\n",
      "Epoch [20/30], Step [100/938], Loss: 0.1998\n",
      "Epoch [20/30], Step [200/938], Loss: 0.1897\n",
      "Epoch [20/30], Step [300/938], Loss: 0.2715\n",
      "Epoch [20/30], Step [400/938], Loss: 0.2154\n",
      "Epoch [20/30], Step [500/938], Loss: 0.2994\n",
      "Epoch [20/30], Step [600/938], Loss: 0.2527\n",
      "Epoch [20/30], Step [700/938], Loss: 0.2260\n",
      "Epoch [20/30], Step [800/938], Loss: 0.1988\n",
      "Epoch [20/30], Step [900/938], Loss: 0.2689\n",
      "Train Accuracy: 97.77%\n",
      "Test Accuracy: 98.68%\n",
      "Test Loss: 0.0402\n",
      "Epoch [21/30], Step [100/938], Loss: 0.2761\n",
      "Epoch [21/30], Step [200/938], Loss: 0.2038\n",
      "Epoch [21/30], Step [300/938], Loss: 0.2069\n",
      "Epoch [21/30], Step [400/938], Loss: 0.2664\n",
      "Epoch [21/30], Step [500/938], Loss: 0.1901\n",
      "Epoch [21/30], Step [600/938], Loss: 0.2714\n",
      "Epoch [21/30], Step [700/938], Loss: 0.2456\n",
      "Epoch [21/30], Step [800/938], Loss: 0.2630\n",
      "Epoch [21/30], Step [900/938], Loss: 0.5135\n",
      "Train Accuracy: 97.69%\n",
      "Test Accuracy: 98.64%\n",
      "Test Loss: 0.0402\n",
      "Epoch [22/30], Step [100/938], Loss: 0.2961\n",
      "Epoch [22/30], Step [200/938], Loss: 0.2224\n",
      "Epoch [22/30], Step [300/938], Loss: 0.2173\n",
      "Epoch [22/30], Step [400/938], Loss: 0.2054\n",
      "Epoch [22/30], Step [500/938], Loss: 0.2146\n",
      "Epoch [22/30], Step [600/938], Loss: 0.1925\n",
      "Epoch [22/30], Step [700/938], Loss: 0.2436\n",
      "Epoch [22/30], Step [800/938], Loss: 0.3213\n",
      "Epoch [22/30], Step [900/938], Loss: 0.4775\n",
      "Train Accuracy: 97.78%\n",
      "Test Accuracy: 98.70%\n",
      "Test Loss: 0.0386\n",
      "Epoch [23/30], Step [100/938], Loss: 0.2981\n",
      "Epoch [23/30], Step [200/938], Loss: 0.3184\n",
      "Epoch [23/30], Step [300/938], Loss: 0.3770\n",
      "Epoch [23/30], Step [400/938], Loss: 0.2084\n",
      "Epoch [23/30], Step [500/938], Loss: 0.2497\n",
      "Epoch [23/30], Step [600/938], Loss: 0.2035\n",
      "Epoch [23/30], Step [700/938], Loss: 0.2164\n",
      "Epoch [23/30], Step [800/938], Loss: 0.3164\n",
      "Epoch [23/30], Step [900/938], Loss: 0.2316\n",
      "Train Accuracy: 97.70%\n",
      "Test Accuracy: 98.65%\n",
      "Test Loss: 0.0420\n",
      "Epoch [24/30], Step [100/938], Loss: 0.2213\n",
      "Epoch [24/30], Step [200/938], Loss: 0.1797\n",
      "Epoch [24/30], Step [300/938], Loss: 0.1986\n",
      "Epoch [24/30], Step [400/938], Loss: 0.2639\n",
      "Epoch [24/30], Step [500/938], Loss: 0.1789\n",
      "Epoch [24/30], Step [600/938], Loss: 0.2345\n",
      "Epoch [24/30], Step [700/938], Loss: 0.2894\n",
      "Epoch [24/30], Step [800/938], Loss: 0.2689\n",
      "Epoch [24/30], Step [900/938], Loss: 0.1874\n",
      "Train Accuracy: 97.74%\n",
      "Test Accuracy: 98.61%\n",
      "Test Loss: 0.0418\n",
      "Epoch [25/30], Step [100/938], Loss: 0.2065\n",
      "Epoch [25/30], Step [200/938], Loss: 0.2467\n",
      "Epoch [25/30], Step [300/938], Loss: 0.2386\n",
      "Epoch [25/30], Step [400/938], Loss: 0.1943\n",
      "Epoch [25/30], Step [500/938], Loss: 0.2054\n",
      "Epoch [25/30], Step [600/938], Loss: 0.1891\n",
      "Epoch [25/30], Step [700/938], Loss: 0.2637\n",
      "Epoch [25/30], Step [800/938], Loss: 0.1808\n",
      "Epoch [25/30], Step [900/938], Loss: 0.2858\n",
      "Train Accuracy: 97.77%\n",
      "Test Accuracy: 98.77%\n",
      "Test Loss: 0.0364\n",
      "Epoch [26/30], Step [100/938], Loss: 0.2643\n",
      "Epoch [26/30], Step [200/938], Loss: 0.3522\n",
      "Epoch [26/30], Step [300/938], Loss: 0.2855\n",
      "Epoch [26/30], Step [400/938], Loss: 0.2352\n",
      "Epoch [26/30], Step [500/938], Loss: 0.1949\n",
      "Epoch [26/30], Step [600/938], Loss: 0.3592\n",
      "Epoch [26/30], Step [700/938], Loss: 0.1842\n",
      "Epoch [26/30], Step [800/938], Loss: 0.2024\n",
      "Epoch [26/30], Step [900/938], Loss: 0.2409\n",
      "Train Accuracy: 97.83%\n",
      "Test Accuracy: 98.33%\n",
      "Test Loss: 0.0472\n",
      "Epoch [27/30], Step [100/938], Loss: 0.2030\n",
      "Epoch [27/30], Step [200/938], Loss: 0.1920\n",
      "Epoch [27/30], Step [300/938], Loss: 0.2042\n",
      "Epoch [27/30], Step [400/938], Loss: 0.1822\n",
      "Epoch [27/30], Step [500/938], Loss: 0.2285\n",
      "Epoch [27/30], Step [600/938], Loss: 0.2926\n",
      "Epoch [27/30], Step [700/938], Loss: 0.2469\n",
      "Epoch [27/30], Step [800/938], Loss: 0.3186\n",
      "Epoch [27/30], Step [900/938], Loss: 0.2014\n",
      "Train Accuracy: 97.86%\n",
      "Test Accuracy: 98.70%\n",
      "Test Loss: 0.0395\n",
      "Epoch [28/30], Step [100/938], Loss: 0.1945\n",
      "Epoch [28/30], Step [200/938], Loss: 0.1834\n",
      "Epoch [28/30], Step [300/938], Loss: 0.2178\n",
      "Epoch [28/30], Step [400/938], Loss: 0.2390\n",
      "Epoch [28/30], Step [500/938], Loss: 0.1921\n",
      "Epoch [28/30], Step [600/938], Loss: 0.2020\n",
      "Epoch [28/30], Step [700/938], Loss: 0.2587\n",
      "Epoch [28/30], Step [800/938], Loss: 0.3086\n",
      "Epoch [28/30], Step [900/938], Loss: 0.2267\n",
      "Train Accuracy: 97.82%\n",
      "Test Accuracy: 98.73%\n",
      "Test Loss: 0.0387\n",
      "Epoch [29/30], Step [100/938], Loss: 0.2895\n",
      "Epoch [29/30], Step [200/938], Loss: 0.2532\n",
      "Epoch [29/30], Step [300/938], Loss: 0.2441\n",
      "Epoch [29/30], Step [400/938], Loss: 0.2575\n",
      "Epoch [29/30], Step [500/938], Loss: 0.2740\n",
      "Epoch [29/30], Step [600/938], Loss: 0.2286\n",
      "Epoch [29/30], Step [700/938], Loss: 0.3401\n",
      "Epoch [29/30], Step [800/938], Loss: 0.4752\n",
      "Epoch [29/30], Step [900/938], Loss: 0.2271\n",
      "Train Accuracy: 97.80%\n",
      "Test Accuracy: 98.73%\n",
      "Test Loss: 0.0387\n",
      "Epoch [30/30], Step [100/938], Loss: 0.2243\n",
      "Epoch [30/30], Step [200/938], Loss: 0.1885\n",
      "Epoch [30/30], Step [300/938], Loss: 0.2085\n",
      "Epoch [30/30], Step [400/938], Loss: 0.2905\n",
      "Epoch [30/30], Step [500/938], Loss: 0.1892\n",
      "Epoch [30/30], Step [600/938], Loss: 0.1889\n",
      "Epoch [30/30], Step [700/938], Loss: 0.3280\n",
      "Epoch [30/30], Step [800/938], Loss: 0.3730\n",
      "Epoch [30/30], Step [900/938], Loss: 0.2885\n",
      "Train Accuracy: 97.76%\n",
      "Test Accuracy: 98.75%\n",
      "Test Loss: 0.0358\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from models.models import CNN, CNN_d\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "\n",
    "# Define the CNN + Dropout architecture with dropout and L1 regularization\n",
    "class CNN_d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_d, self).__init__()\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.25)  # Added dropout\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)  # Added dropout\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)  # Added dropout\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout2(x)  # Added dropout\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#  Create an instance of the CNN\n",
    "model = CNN_d().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "l1_lambda = 0.0001  # L1 regularization lambda value\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=l1_lambda)\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create an instance of the CNN with L1 regularization\n",
    "model = CNN_d().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=l1_lambda)\n",
    "\n",
    "# Initialize lists to store the train and test losses for each epoch\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # L1 regularization\n",
    "        l1_regularization = torch.tensor(0., device=device)\n",
    "        for param in model.parameters():\n",
    "            l1_regularization += torch.norm(param, 1)\n",
    "        loss += l1_lambda * l1_regularization\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    print(f'Train Accuracy: {(100 * correct / total):.2f}%')\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    # Print test accuracy at the end of each epoch\n",
    "    test_accuracy = (100 * correct / total)\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd5c986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   0 1131    0    2    0    1    0    1    0    0]\n",
      " [   3    5 1012    1    0    1    1    6    2    1]\n",
      " [   0    0    3  998    0    4    0    2    1    2]\n",
      " [   0    1    0    0  970    0    2    0    1    8]\n",
      " [   2    0    0    2    0  884    2    1    0    1]\n",
      " [   5    2    0    1    1    3  946    0    0    0]\n",
      " [   0    3    8    0    0    0    0 1013    1    3]\n",
      " [   2    2    0    1    1    1    2    1  960    4]\n",
      " [   4    3    0    0    4    5    0    5    3  985]]\n"
     ]
    }
   ],
   "source": [
    "# Plot the train and test losses for each epoch\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display the confusion matrix\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a63bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
